{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA instead of feature selection\n",
    "single model od adhda and sex f remove and use multiple\n",
    "remove garphs and just classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1213, 1213, 1213, 1213)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_excel(r'C:\\Users\\abdur\\vs_code\\sidra\\widsdatathon2025\\TRAIN\\TRAINING_SOLUTIONS.xlsx')\n",
    "categorical = pd.read_excel(r'C:\\Users\\abdur\\vs_code\\sidra\\widsdatathon2025\\TRAIN\\TRAIN_CATEGORICAL_METADATA.xlsx')\n",
    "function = pd.read_csv(r'C:\\Users\\abdur\\vs_code\\sidra\\widsdatathon2025\\TRAIN\\TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
    "quantitative = pd.read_excel(r'C:\\Users\\abdur\\vs_code\\sidra\\widsdatathon2025\\TRAIN\\TRAIN_QUANTITATIVE_METADATA.xlsx')\n",
    "\n",
    "target.shape, categorical.shape, function.shape,quantitative.shape\n",
    "len(target['participant_id'].unique()),\\\n",
    "len(categorical['participant_id'].unique()),\\\n",
    "len(function['participant_id'].unique()),\\\n",
    "len(quantitative['participant_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (1213, 19930)\n"
     ]
    }
   ],
   "source": [
    "def get_feats(mode='TRAIN'):\n",
    "    # Define base dataset path\n",
    "    base_path = r'C:\\Users\\abdur\\vs_code\\sidra\\widsdatathon2025'\n",
    "    mode_path = os.path.join(base_path, mode)\n",
    "    \n",
    "    # Load quantitative metadata\n",
    "    feats = pd.read_excel(os.path.join(mode_path, f'{mode}_QUANTITATIVE_METADATA.xlsx'), engine='openpyxl')\n",
    "    \n",
    "    # Load categorical metadata with correct filename depending on mode\n",
    "    if mode == 'TRAIN':\n",
    "        cate_path = os.path.join(mode_path, f'{mode}_CATEGORICAL_METADATA.xlsx')\n",
    "    else:\n",
    "        cate_path = os.path.join(mode_path, f'{mode}_CATEGORICAL.xlsx')\n",
    "    \n",
    "    cate = pd.read_excel(cate_path, engine='openpyxl')\n",
    "    \n",
    "    # Merge categorical data\n",
    "    feats = feats.merge(cate, on='participant_id', how='left')\n",
    "    \n",
    "    # Load functional connectome matrices\n",
    "    func = pd.read_csv(os.path.join(mode_path, f'{mode}_FUNCTIONAL_CONNECTOME_MATRICES.csv'))\n",
    "    feats = feats.merge(func, on='participant_id', how='left')\n",
    "    \n",
    "    # If training data, merge with solution file\n",
    "    if mode == 'TRAIN':\n",
    "        solution_path = os.path.join(mode_path, 'TRAINING_SOLUTIONS.xlsx')\n",
    "        solution = pd.read_excel(solution_path, engine='openpyxl')\n",
    "        feats = feats.merge(solution, on='participant_id', how='left')\n",
    "    \n",
    "    return feats\n",
    "# Load the combined dataset for training\n",
    "df_train = get_feats('TRAIN')\n",
    "print(\"Final dataset shape:\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1213, 19930) (304, 19928)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>EHQ_EHQ_Total</th>\n",
       "      <th>ColorVision_CV_Score</th>\n",
       "      <th>APQ_P_APQ_P_CP</th>\n",
       "      <th>APQ_P_APQ_P_ID</th>\n",
       "      <th>APQ_P_APQ_P_INV</th>\n",
       "      <th>APQ_P_APQ_P_OPD</th>\n",
       "      <th>APQ_P_APQ_P_PM</th>\n",
       "      <th>APQ_P_APQ_P_PP</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>...</th>\n",
       "      <th>195throw_198thcolumn</th>\n",
       "      <th>195throw_199thcolumn</th>\n",
       "      <th>196throw_197thcolumn</th>\n",
       "      <th>196throw_198thcolumn</th>\n",
       "      <th>196throw_199thcolumn</th>\n",
       "      <th>197throw_198thcolumn</th>\n",
       "      <th>197throw_199thcolumn</th>\n",
       "      <th>198throw_199thcolumn</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UmrK0vMLopoR</td>\n",
       "      <td>40.00</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058396</td>\n",
       "      <td>-0.041544</td>\n",
       "      <td>0.142806</td>\n",
       "      <td>-0.006377</td>\n",
       "      <td>0.108005</td>\n",
       "      <td>0.148327</td>\n",
       "      <td>0.093230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPaeQkhcjg7d</td>\n",
       "      <td>-94.47</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025624</td>\n",
       "      <td>-0.031863</td>\n",
       "      <td>0.162011</td>\n",
       "      <td>0.067439</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.088893</td>\n",
       "      <td>0.064094</td>\n",
       "      <td>0.194381</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nb4EetVPm3gs</td>\n",
       "      <td>-46.67</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>-0.044341</td>\n",
       "      <td>0.128386</td>\n",
       "      <td>0.047282</td>\n",
       "      <td>0.087678</td>\n",
       "      <td>0.146221</td>\n",
       "      <td>-0.009425</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4vPhVu91o4b</td>\n",
       "      <td>-26.68</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007152</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>0.121726</td>\n",
       "      <td>0.045089</td>\n",
       "      <td>0.154464</td>\n",
       "      <td>0.106817</td>\n",
       "      <td>0.065336</td>\n",
       "      <td>0.234708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M09PXs7arQ5E</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010196</td>\n",
       "      <td>0.035638</td>\n",
       "      <td>0.074978</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.118199</td>\n",
       "      <td>0.112522</td>\n",
       "      <td>0.143666</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  \\\n",
       "0   UmrK0vMLopoR          40.00                    13               3   \n",
       "1   CPaeQkhcjg7d         -94.47                    14               3   \n",
       "2   Nb4EetVPm3gs         -46.67                    14               4   \n",
       "3   p4vPhVu91o4b         -26.68                    10               5   \n",
       "4   M09PXs7arQ5E           0.00                    14               5   \n",
       "\n",
       "   APQ_P_APQ_P_ID  APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  APQ_P_APQ_P_PM  \\\n",
       "0              10               47               13              11   \n",
       "1              13               34               18              23   \n",
       "2              10               35               16              10   \n",
       "3              12               39               19              16   \n",
       "4              15               40               20              24   \n",
       "\n",
       "   APQ_P_APQ_P_PP  SDQ_SDQ_Conduct_Problems  ...  195throw_198thcolumn  \\\n",
       "0              28                         0  ...             -0.058396   \n",
       "1              30                         0  ...             -0.025624   \n",
       "2              29                         1  ...              0.010771   \n",
       "3              28                         6  ...             -0.007152   \n",
       "4              28                         1  ...             -0.010196   \n",
       "\n",
       "   195throw_199thcolumn  196throw_197thcolumn  196throw_198thcolumn  \\\n",
       "0             -0.041544              0.142806             -0.006377   \n",
       "1             -0.031863              0.162011              0.067439   \n",
       "2             -0.044341              0.128386              0.047282   \n",
       "3              0.032584              0.121726              0.045089   \n",
       "4              0.035638              0.074978              0.030579   \n",
       "\n",
       "   196throw_199thcolumn  197throw_198thcolumn  197throw_199thcolumn  \\\n",
       "0              0.108005              0.148327              0.093230   \n",
       "1              0.017155              0.088893              0.064094   \n",
       "2              0.087678              0.146221             -0.009425   \n",
       "3              0.154464              0.106817              0.065336   \n",
       "4              0.025640              0.118199              0.112522   \n",
       "\n",
       "   198throw_199thcolumn  ADHD_Outcome  Sex_F  \n",
       "0             -0.004984             1      1  \n",
       "1              0.194381             1      0  \n",
       "2              0.035150             1      0  \n",
       "3              0.234708             1      1  \n",
       "4              0.143666             1      1  \n",
       "\n",
       "[5 rows x 19930 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = get_feats(mode='TRAIN')\n",
    "test_df = get_feats(mode='TEST')\n",
    "print (train_df.shape, test_df.shape)\n",
    "# Display the first few rows of the training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>EHQ_EHQ_Total</th>\n",
       "      <th>ColorVision_CV_Score</th>\n",
       "      <th>APQ_P_APQ_P_CP</th>\n",
       "      <th>APQ_P_APQ_P_ID</th>\n",
       "      <th>APQ_P_APQ_P_INV</th>\n",
       "      <th>APQ_P_APQ_P_OPD</th>\n",
       "      <th>APQ_P_APQ_P_PM</th>\n",
       "      <th>APQ_P_APQ_P_PP</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>...</th>\n",
       "      <th>195throw_196thcolumn</th>\n",
       "      <th>195throw_197thcolumn</th>\n",
       "      <th>195throw_198thcolumn</th>\n",
       "      <th>195throw_199thcolumn</th>\n",
       "      <th>196throw_197thcolumn</th>\n",
       "      <th>196throw_198thcolumn</th>\n",
       "      <th>196throw_199thcolumn</th>\n",
       "      <th>197throw_198thcolumn</th>\n",
       "      <th>197throw_199thcolumn</th>\n",
       "      <th>198throw_199thcolumn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cfwaf5FX7jWK</td>\n",
       "      <td>60.03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080423</td>\n",
       "      <td>-0.054581</td>\n",
       "      <td>-0.088163</td>\n",
       "      <td>-0.028574</td>\n",
       "      <td>0.444847</td>\n",
       "      <td>0.350149</td>\n",
       "      <td>-0.012601</td>\n",
       "      <td>0.665750</td>\n",
       "      <td>0.560565</td>\n",
       "      <td>0.555732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhGrzmvA3Hjq</td>\n",
       "      <td>86.71</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198009</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.083122</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.687497</td>\n",
       "      <td>0.306229</td>\n",
       "      <td>0.717485</td>\n",
       "      <td>0.461809</td>\n",
       "      <td>0.559632</td>\n",
       "      <td>0.350027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ULliyEXjy4OV</td>\n",
       "      <td>26.68</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051319</td>\n",
       "      <td>0.023630</td>\n",
       "      <td>-0.056819</td>\n",
       "      <td>0.117396</td>\n",
       "      <td>0.576086</td>\n",
       "      <td>0.517831</td>\n",
       "      <td>0.527044</td>\n",
       "      <td>0.605038</td>\n",
       "      <td>0.609856</td>\n",
       "      <td>0.750987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LZfeAb1xMtql</td>\n",
       "      <td>93.38</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046183</td>\n",
       "      <td>-0.238962</td>\n",
       "      <td>0.121868</td>\n",
       "      <td>-0.260970</td>\n",
       "      <td>0.646818</td>\n",
       "      <td>0.594902</td>\n",
       "      <td>0.608156</td>\n",
       "      <td>0.595459</td>\n",
       "      <td>0.683189</td>\n",
       "      <td>0.542296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EnFOUv0YK1RG</td>\n",
       "      <td>-93.38</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315734</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.290791</td>\n",
       "      <td>0.344149</td>\n",
       "      <td>0.480214</td>\n",
       "      <td>0.539824</td>\n",
       "      <td>0.447322</td>\n",
       "      <td>0.293088</td>\n",
       "      <td>0.148529</td>\n",
       "      <td>0.539823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19928 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  \\\n",
       "0   Cfwaf5FX7jWK          60.03                  14.0             5.0   \n",
       "1   vhGrzmvA3Hjq          86.71                  12.0             3.0   \n",
       "2   ULliyEXjy4OV          26.68                  13.0             3.0   \n",
       "3   LZfeAb1xMtql          93.38                  13.0             3.0   \n",
       "4   EnFOUv0YK1RG         -93.38                  14.0             3.0   \n",
       "\n",
       "   APQ_P_APQ_P_ID  APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  APQ_P_APQ_P_PM  \\\n",
       "0            16.0             41.0             19.0            11.0   \n",
       "1            13.0             43.0             18.0            15.0   \n",
       "2            14.0             36.0             16.0            14.0   \n",
       "3            19.0             41.0             17.0            18.0   \n",
       "4            13.0             42.0             19.0            16.0   \n",
       "\n",
       "   APQ_P_APQ_P_PP  SDQ_SDQ_Conduct_Problems  ...  195throw_196thcolumn  \\\n",
       "0            26.0                       2.0  ...              0.080423   \n",
       "1            28.0                       2.0  ...              0.198009   \n",
       "2            25.0                       1.0  ...              0.051319   \n",
       "3            27.0                       4.0  ...              0.046183   \n",
       "4            28.0                       2.0  ...              0.315734   \n",
       "\n",
       "   195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n",
       "0             -0.054581             -0.088163             -0.028574   \n",
       "1             -0.000724              0.083122              0.033043   \n",
       "2              0.023630             -0.056819              0.117396   \n",
       "3             -0.238962              0.121868             -0.260970   \n",
       "4              0.002234              0.290791              0.344149   \n",
       "\n",
       "   196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n",
       "0              0.444847              0.350149             -0.012601   \n",
       "1              0.687497              0.306229              0.717485   \n",
       "2              0.576086              0.517831              0.527044   \n",
       "3              0.646818              0.594902              0.608156   \n",
       "4              0.480214              0.539824              0.447322   \n",
       "\n",
       "   197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n",
       "0              0.665750              0.560565              0.555732  \n",
       "1              0.461809              0.559632              0.350027  \n",
       "2              0.605038              0.609856              0.750987  \n",
       "3              0.595459              0.683189              0.542296  \n",
       "4              0.293088              0.148529              0.539823  \n",
       "\n",
       "[5 rows x 19928 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'participant_id' column\n",
    "train_df = train_df.drop(columns=['participant_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of columns:\n",
      "EHQ_EHQ_Total           float64\n",
      "ColorVision_CV_Score      int64\n",
      "APQ_P_APQ_P_CP            int64\n",
      "APQ_P_APQ_P_ID            int64\n",
      "APQ_P_APQ_P_INV           int64\n",
      "                         ...   \n",
      "197throw_198thcolumn    float64\n",
      "197throw_199thcolumn    float64\n",
      "198throw_199thcolumn    float64\n",
      "ADHD_Outcome              int64\n",
      "Sex_F                     int64\n",
      "Length: 19929, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get data types of all columns\n",
    "print(\"Data types of columns:\")\n",
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 50 rows of train_df\n",
    "train_df_50 = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "EHQ_EHQ_Total           0\n",
      "ColorVision_CV_Score    0\n",
      "APQ_P_APQ_P_CP          0\n",
      "APQ_P_APQ_P_ID          0\n",
      "APQ_P_APQ_P_INV         0\n",
      "                       ..\n",
      "197throw_198thcolumn    0\n",
      "197throw_199thcolumn    0\n",
      "198throw_199thcolumn    0\n",
      "ADHD_Outcome            0\n",
      "Sex_F                   0\n",
      "Length: 19929, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(train_df_50.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (Ensure train_df_50 is already loaded before running this code)\n",
    "# Extract labels if they are part of train_df_50\n",
    "if 'labels' not in globals():\n",
    "    labels = train_df_50[[\"ADHD_Outcome\", \"Sex_F\"]].copy()  # Extract labels from train_df_50\n",
    "\n",
    "# 1. Drop columns\n",
    "drop_cols = [\n",
    "    \"Basic_Demos_Study_Site\", \"MRI_Track_Scan_Location\", \"PreInt_Demos_Fam_Child_Ethnicity\",\n",
    "    \"PreInt_Demos_Fam_Child_Race\", 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Occ'\n",
    "]\n",
    "train_df_50 = train_df_50.drop(columns=drop_cols, errors='ignore')  # Avoid errors if column missing\n",
    "\n",
    "# 2. Remove non-numeric columns before scaling\n",
    "numeric_cols = train_df_50.select_dtypes(include=[np.number]).columns  # Keep only numeric columns\n",
    "train_df_50 = train_df_50[numeric_cols]  # Drop categorical or object columns\n",
    "\n",
    "# 3. Normalize features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_df_50.iloc[:, :] = scaler.fit_transform(train_df_50)\n",
    "\n",
    "\n",
    "# 5. Retrieve target variables\n",
    "y_adhd = labels[\"ADHD_Outcome\"].copy()\n",
    "y_sex = labels[\"Sex_F\"].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[1 0]\n",
      "ADHD_Outcome\n",
      "1    831\n",
      "0    382\n",
      "Name: count, dtype: int64\n",
      "Sex_F\n",
      "0    797\n",
      "1    416\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df_50[\"ADHD_Outcome\"].unique())\n",
    "print(train_df_50[\"Sex_F\"].unique())\n",
    "print(train_df_50[\"ADHD_Outcome\"].value_counts())\n",
    "print(train_df_50[\"Sex_F\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADHD_Outcome\n",
      "1    0.685078\n",
      "0    0.314922\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ADHD_Outcome'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abdur\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'ADHD_Outcome'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(train_df_50[\u001b[33m'\u001b[39m\u001b[33mADHD_Outcome\u001b[39m\u001b[33m'\u001b[39m].value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m))  \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mADHD_Outcome\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m))  \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abdur\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abdur\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'ADHD_Outcome'"
     ]
    }
   ],
   "source": [
    "print(train_df_50['ADHD_Outcome'].value_counts(normalize=True))  \n",
    "print(test_df['ADHD_Outcome'].value_counts(normalize=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the filtered features dataset for training.\n",
      "Training data shape: (1213, 17)\n",
      "Using provided test dataset parameter.\n",
      "Test data shape: (304, 19928)\n",
      "Original number of features: 15\n",
      "\n",
      "Training data NaN values: 0\n",
      "Test data NaN values: 285\n",
      "\n",
      "Preprocessing data with NaN handling...\n",
      "Identified 10 behavioral features:\n",
      "SDQ_SDQ_Hyperactivity, SDQ_SDQ_Externalizing, SDQ_SDQ_Difficulties_Total, SDQ_SDQ_Generating_Impact, SDQ_SDQ_Conduct_Problems, SDQ_SDQ_Internalizing, SDQ_SDQ_Emotional_Problems, SDQ_SDQ_Prosocial, SDQ_SDQ_Peer_Problems, APQ_P_APQ_P_OPD\n",
      "Created 45 interaction terms between behavioral features\n",
      "Created 45 interaction terms between behavioral features\n",
      "\n",
      "Performing feature selection on interaction features...\n",
      "Selecting features for ADHD_Outcome...\n",
      "Selecting features for Sex_F...\n",
      "Selected 12 features for ADHD_Outcome (7 interactions)\n",
      "Selected 18 features for Sex_F (14 interactions)\n",
      "\n",
      "Applying SMOTE-ENN for balanced sampling...\n",
      "Balancing ADHD_Outcome data...\n",
      "Balancing Sex_F data...\n",
      "Original ADHD class distribution: [305 665]\n",
      "Resampled ADHD class distribution: [481 366]\n",
      "Original Sex_F class distribution: [637 333]\n",
      "Resampled Sex_F class distribution: [183 356]\n",
      "\n",
      "Training models with feature interactions...\n",
      "Training XGBoost model for ADHD_Outcome...\n",
      "Training XGBoost model for Sex_F...\n",
      "\n",
      "Finding optimal thresholds for high sensitivity...\n",
      "\n",
      "Optimized Thresholds for High Sensitivity:\n",
      "ADHD_Outcome Threshold: 0.0500\n",
      "  Sensitivity: 0.8976, Specificity: 0.5714\n",
      "  Accuracy: 0.7942\n",
      "Sex_F Threshold: 0.0800\n",
      "  Sensitivity: 0.9036, Specificity: 0.1125\n",
      "  Accuracy: 0.3827\n",
      "\n",
      "ADHD_Outcome AUC: 0.8127\n",
      "Sex_F AUC: 0.6078\n",
      "\n",
      "High sensitivity threshold plot saved to: high_sensitivity_threshold.png\n",
      "\n",
      "Retraining models on full dataset...\n",
      "\n",
      "Generating predictions for test data with high sensitivity threshold...\n",
      "\n",
      "High sensitivity predictions saved to: optimized_thresholds_predictions_high_sensitivity.csv\n",
      "Detailed prediction data saved to: optimized_thresholds_predictions_high_sensitivity_details.csv\n",
      "\n",
      "Formatted predictions (High Sensitivity Threshold):\n",
      "participant_id,ADHD_Outcome,Sex_F\n",
      "Cfwaf5FX7jWK, 1, 1\n",
      "vhGrzmvA3Hjq, 1, 1\n",
      "ULliyEXjy4OV, 1, 1\n",
      "LZfeAb1xMtql, 1, 1\n",
      "EnFOUv0YK1RG, 1, 1\n",
      "3VbkvJ22j9Fu, 1, 1\n",
      "PRKZcnOgqcuk, 1, 1\n",
      "DuVUuyMZi5qV, 1, 1\n",
      "uM4etVLZrgMg, 1, 1\n",
      "BpzyExrET5ta, 1, 1\n",
      "sAqeb6F4lz97, 1, 1\n",
      "u7XOOvHirIx7, 1, 1\n",
      "aEPm4bEQvbYi, 1, 1\n",
      "Fj9A5PWsIWKT, 1, 1\n",
      "19mb5yGJigtw, 1, 0\n",
      "v1nMpCoLGU0V, 1, 1\n",
      "hRPuz4zpsEbw, 1, 1\n",
      "mT8A6xa1O4Ro, 1, 1\n",
      "4QBTjDoVpVt6, 1, 1\n",
      "0X2H4LroxZcw, 1, 1\n",
      "9CH7UxXuznUa, 1, 1\n",
      "nU73zzjTnr4A, 1, 1\n",
      "uEZHGukIUQ0k, 1, 1\n",
      "jCzQwkpfgZyQ, 1, 1\n",
      "Ljvrs76QJuI5, 1, 1\n",
      "IbF3zW0Wbx4Q, 1, 1\n",
      "UHnGiDNksa0x, 1, 1\n",
      "yYjiJsx8PM48, 1, 1\n",
      "1j28gfEoCQ3o, 1, 1\n",
      "dC5XvD5A3tqo, 1, 1\n",
      "5irK4m6otW7R, 1, 1\n",
      "88IME13c7xDB, 1, 1\n",
      "GYQvyFy7QF7z, 1, 1\n",
      "rZ4Djyg4w7Yv, 1, 1\n",
      "g7OzSuPQs2wx, 0, 1\n",
      "7gx6bnmZrxKv, 1, 1\n",
      "sslRc6ajaOkD, 1, 1\n",
      "h5xmGEy5uNA9, 1, 1\n",
      "sQaDS15dgJw7, 1, 1\n",
      "erkdzShJ7zHD, 1, 1\n",
      "xb3e1IzlY1QV, 1, 1\n",
      "hAY3GGKYCKNz, 1, 1\n",
      "Qf7YnjK9A9Nr, 1, 1\n",
      "pJXKagbu6k5J, 1, 1\n",
      "GusOn8clPEcS, 1, 1\n",
      "HynLNt7eOUu6, 0, 1\n",
      "VHaWyqk3brmj, 1, 1\n",
      "XsnFuC5RuxEj, 1, 1\n",
      "fJ18nx0flUWU, 1, 1\n",
      "z0TcjaAHc8af, 1, 1\n",
      "cwhzTO0Vu9fs, 0, 1\n",
      "FJ14ni1wdpx0, 1, 1\n",
      "LbvK4T5h6Bgg, 1, 1\n",
      "g8nC5onuX4Iu, 1, 1\n",
      "X8fHsDpoMCrc, 1, 1\n",
      "9MLL7pYQEsHg, 1, 1\n",
      "Rl4ewZ2JsYiu, 1, 1\n",
      "NPqPE9t9ANPY, 1, 1\n",
      "xdNPzLAsxshh, 1, 0\n",
      "Fkys1lBZ0EYl, 1, 1\n",
      "9bB7cb8GIt55, 1, 1\n",
      "S2aUm7iSCh8K, 1, 1\n",
      "uMXsb9zvFhZG, 1, 1\n",
      "WswtU2xjkwrJ, 1, 0\n",
      "NUD1SQ26nGwx, 1, 1\n",
      "1lqQa6Bvsvgo, 1, 1\n",
      "nLIxzOqeY0F8, 1, 1\n",
      "ZnpZwNyveSC1, 1, 1\n",
      "g065FaS0cDJw, 1, 1\n",
      "5nPxL5XWeWqT, 1, 1\n",
      "PXgJvd8UZ9fe, 1, 1\n",
      "bRHXqarRnTOl, 1, 1\n",
      "iC4lUrNmd76W, 1, 1\n",
      "e5PO7MIzpSKp, 1, 1\n",
      "iQ5WKoVa0Oe8, 0, 1\n",
      "1zYwUOsWtWUO, 1, 1\n",
      "9dIzgZgU0t2O, 1, 1\n",
      "FZZFnxIITvIb, 1, 1\n",
      "UZ4wZJktSjXM, 1, 1\n",
      "47cpL5bSIaes, 1, 1\n",
      "cD8B0lz9W1Cc, 1, 1\n",
      "RBUqOe8h6Rjz, 1, 1\n",
      "xMcjmmscXHRg, 1, 1\n",
      "zIkbsyNlTbCK, 1, 1\n",
      "eqXWWdeNFQoH, 1, 1\n",
      "FUBvB3niWLlN, 1, 1\n",
      "RZKV9tFLkC9q, 1, 1\n",
      "YX2nejjQrjTE, 1, 1\n",
      "9uCWNQLzILyS, 1, 1\n",
      "PJvfoHAcsFop, 1, 1\n",
      "rsQPeuxeuzFN, 1, 1\n",
      "xgRkRXFj22eG, 1, 1\n",
      "NSvVb4rAbXKU, 1, 1\n",
      "rY7ztwsrfyfe, 1, 1\n",
      "0idudG3MZeOR, 1, 1\n",
      "tbZrR9R4zdPW, 1, 1\n",
      "mmW5cD4mDCyK, 1, 1\n",
      "FvnoZ1q1rX2c, 1, 1\n",
      "rIE98UuGpsXN, 1, 1\n",
      "a4NfOjK4u0pw, 1, 1\n",
      "x0tFPjGEtTDo, 1, 1\n",
      "Lf1aRmgJMGzn, 1, 1\n",
      "qxDaOMmN2fGr, 1, 1\n",
      "jZz3FS9Lxw7Y, 1, 1\n",
      "EQdMyNMDvWuv, 1, 1\n",
      "fpbYYqEmKmBP, 1, 1\n",
      "Ljl0uwPY3cHC, 1, 1\n",
      "h5uHyT7ZsggG, 1, 1\n",
      "REHeZZWpqbXA, 1, 1\n",
      "WDaVjmgqDtdH, 1, 1\n",
      "JPbjWX5WRMo5, 1, 1\n",
      "m4i3mVopmQND, 1, 1\n",
      "8js31yKXtVtT, 1, 1\n",
      "ThzfJlzfC5zm, 1, 1\n",
      "PKmY55L3l7nh, 1, 1\n",
      "EjMbGKIXc6xh, 1, 1\n",
      "hRtu2jZGjsqu, 1, 1\n",
      "wE08jf7axl4G, 1, 1\n",
      "oFqFWjZvQpdq, 1, 1\n",
      "rZRMMWCz9o54, 1, 1\n",
      "7bH7tOSH8tyL, 1, 1\n",
      "VsAjWDqZH10d, 1, 1\n",
      "mca5wy8JcazG, 1, 1\n",
      "LsErFKyD0Amx, 1, 1\n",
      "7v5DsWe80ek1, 1, 0\n",
      "idllOUP39Yoy, 1, 0\n",
      "Wm8vHtUOTSdK, 1, 1\n",
      "lIo1EopEayvT, 1, 1\n",
      "ceMWzYEKDxGS, 1, 1\n",
      "RfNlGWXzHH3K, 1, 1\n",
      "nLaCfgOfeeux, 1, 1\n",
      "hHbDtQpct0sM, 1, 1\n",
      "xctrrQN3v50J, 1, 1\n",
      "sdJvoGXQsxzG, 1, 1\n",
      "na1higV3BYix, 0, 1\n",
      "iUhm6elzNZnR, 1, 1\n",
      "IDLPcayOzo7t, 1, 1\n",
      "Z0CZjkr8SDlo, 1, 1\n",
      "ddE1W1SfgV7E, 1, 1\n",
      "duMJcIFRvvUn, 1, 1\n",
      "Ya9QbWu9Oyj7, 1, 1\n",
      "aJeuvuedrbei, 1, 1\n",
      "rUXfpz4ZIVqs, 1, 1\n",
      "66ATazbm1n2H, 1, 1\n",
      "gf8iAJH7Y6LW, 0, 1\n",
      "T3jFzkEFn2lB, 1, 1\n",
      "eAEV7RHPm4gn, 1, 1\n",
      "MOjMYkTSkCT0, 1, 1\n",
      "fLsk0v5A9QWD, 1, 1\n",
      "e4u1878wt5Vu, 1, 1\n",
      "ZssVYalOAWOn, 1, 1\n",
      "eFGeJZyaYTfW, 1, 1\n",
      "DgwxZPoFWSFV, 1, 1\n",
      "vCYoh5kuBxBn, 1, 1\n",
      "DkwrzlcjCXzl, 1, 1\n",
      "pQk5LK9WWNlU, 1, 1\n",
      "4TfoOtVqQGIS, 1, 1\n",
      "xm87i9BWm3LH, 1, 1\n",
      "HfAWB7M67jZ7, 1, 1\n",
      "CHEK30GPB53F, 1, 1\n",
      "0ImS6uhE3Ie9, 1, 1\n",
      "x2HGm8Cdw3pH, 1, 1\n",
      "rUhntCqf0veY, 1, 1\n",
      "lviw20KdXmyz, 1, 1\n",
      "EUN1xz5MmK3h, 1, 1\n",
      "JHgSIO5g9kyN, 1, 1\n",
      "HuavjkfJT3Ra, 1, 1\n",
      "jRKvisBZEvMV, 1, 1\n",
      "T7MMp5ZjZIP7, 1, 1\n",
      "7Y5dXDvM5JlW, 1, 1\n",
      "xsEm3scLKQqx, 1, 1\n",
      "CZ6cLlIFT8C7, 1, 1\n",
      "Nm0QSvXNt8IL, 1, 1\n",
      "ZVJtXjkAAp8k, 1, 1\n",
      "kxJ2iDDo7le7, 1, 1\n",
      "KlEGztcVpqQM, 1, 1\n",
      "SEpZVWxwPwzJ, 1, 1\n",
      "3ex9wBx3bXzf, 1, 1\n",
      "GtKTU9RdYH88, 1, 1\n",
      "pXjemmrXv9XU, 1, 1\n",
      "G4HH3C3252g1, 0, 1\n",
      "i103EbS97ZlA, 1, 1\n",
      "V62GcAZSGGHt, 0, 1\n",
      "7uXcG7moAMys, 1, 1\n",
      "MGSeDY5xsLcH, 1, 1\n",
      "HEv7u3wwBUID, 1, 1\n",
      "0joIpvJZmHlM, 1, 1\n",
      "R1WkyITqb6j5, 1, 1\n",
      "y1YkOqsv0518, 1, 1\n",
      "8uNQKfpBZKGT, 1, 1\n",
      "FMKnba82Blol, 1, 1\n",
      "JOL7WOOECWqz, 1, 1\n",
      "c4XMogBDs3JV, 1, 1\n",
      "Aqr7TbYLogDt, 1, 1\n",
      "cWVOYIyTGoPW, 1, 1\n",
      "5F9KuchRWc28, 1, 1\n",
      "GpBWQZEEB8Na, 1, 1\n",
      "1nuCB3iu56Ao, 1, 1\n",
      "tcKZk7TJNjXP, 0, 1\n",
      "Bf8xkS0DgEdq, 1, 1\n",
      "UOohdAfiU2WX, 1, 1\n",
      "CdwfVAJW6U21, 1, 1\n",
      "K3TeYDSt1D69, 1, 1\n",
      "7UT8iirSGhRL, 1, 0\n",
      "q4kyWzfZIqDG, 1, 1\n",
      "06HFIpqKfXy9, 1, 1\n",
      "ZjFv6ztsCBLY, 1, 1\n",
      "rpLRzoX7qzUA, 1, 1\n",
      "tgxIaIPsvpIG, 1, 1\n",
      "iq3Izns35R7e, 1, 1\n",
      "rcUdzoimoCO3, 0, 1\n",
      "RlH1HdX1zOXp, 1, 1\n",
      "sPSXo6gaMyoT, 1, 1\n",
      "i4PoyNNskpN2, 1, 1\n",
      "NppPTQNMYrDr, 1, 1\n",
      "b2MRYJQHtN4Q, 1, 1\n",
      "Z1USdfsVnnjw, 1, 1\n",
      "Cm1JesyqVvvU, 1, 1\n",
      "wfHMTWwtSFnV, 1, 1\n",
      "ZH3fhLHNBy2N, 0, 1\n",
      "zHoI2y6ghT8f, 1, 1\n",
      "5gde2X56TEaV, 1, 1\n",
      "h1NsELdECZtN, 1, 1\n",
      "WVyjBIVNp84k, 1, 1\n",
      "I7wdCrc41LkV, 1, 1\n",
      "dYeoDCtqrZOk, 1, 1\n",
      "gTo2ZwRYwLIM, 1, 1\n",
      "cS46aS2dNkWt, 1, 1\n",
      "0Dua0TUw4sNZ, 1, 1\n",
      "Bct9jCffkwTU, 1, 1\n",
      "0wdp92SlZ6os, 1, 1\n",
      "3ymvGMbsXkDa, 1, 1\n",
      "3CHeLp88N9PU, 1, 1\n",
      "3GuHHSzexdrD, 1, 1\n",
      "BxG4CGNyBthY, 1, 1\n",
      "r1kJWdiLnlzB, 1, 1\n",
      "PHcnlHPVth3A, 1, 1\n",
      "JjO5xmUVZlHV, 1, 1\n",
      "uhrbzFdVttif, 1, 1\n",
      "vFUC44u3e6yc, 1, 1\n",
      "KK1MoDOaknzz, 1, 1\n",
      "xeGDqEHl50Pe, 1, 1\n",
      "MbnL2SsZ3SfN, 1, 0\n",
      "lzsnunuLD5E9, 1, 1\n",
      "ypPOBnAE3X5L, 1, 1\n",
      "t6Yc857Xm0G1, 1, 1\n",
      "IFfLWRuXYCud, 1, 1\n",
      "mMKlS7Xx90To, 1, 1\n",
      "4SP0VjzBYTnA, 1, 1\n",
      "6g9qhyTboWDX, 1, 1\n",
      "zoCHkxMZDLeD, 1, 1\n",
      "J6jcTOKF9FKI, 1, 1\n",
      "knYPTVqlhOOe, 1, 1\n",
      "6mGSjnkluhCm, 1, 1\n",
      "CHK7PetkESpw, 1, 1\n",
      "KOhyaYYWH4J7, 1, 1\n",
      "0VHL9SCh2TfC, 1, 1\n",
      "kA6qrwNv3TVN, 1, 1\n",
      "mby0aqc4xfJt, 0, 1\n",
      "ukPFRpacqtjF, 1, 1\n",
      "JDCneyZ2d8oS, 1, 1\n",
      "frwFik2vzPpk, 1, 1\n",
      "MdR8Vu1UGsUh, 1, 0\n",
      "fQDGE3yvi8JG, 1, 1\n",
      "cMG1xz902zCv, 1, 1\n",
      "czseCZwxGu9b, 1, 1\n",
      "EqjgIpp1uQFT, 1, 1\n",
      "SU2iR4dZt71Q, 1, 1\n",
      "Y8y8VL92UXUp, 1, 1\n",
      "iIM7qDzkFHrK, 0, 1\n",
      "tcvQwlcXDrjM, 1, 1\n",
      "E5WW2AJI3cmY, 1, 1\n",
      "so28UOwqRGcv, 0, 1\n",
      "JhsrI2yTZUCS, 1, 1\n",
      "pVZ5eyvBxRXh, 1, 1\n",
      "8OuOUWiYizQT, 1, 1\n",
      "22mg5880yUSV, 1, 1\n",
      "OCfNYCcRM3dw, 1, 1\n",
      "PDtAgNUCR1F1, 1, 1\n",
      "nJJWVTrUPKHh, 1, 1\n",
      "8GLRwVrATqDq, 1, 1\n",
      "geK1iR863siE, 1, 1\n",
      "9OsyiuTB9ARL, 1, 1\n",
      "ZoX0gx0mL2fe, 1, 1\n",
      "7U96jnm3G0nL, 1, 1\n",
      "8RcAlHO2Z7Z5, 1, 1\n",
      "Il8Z3DuXaX9D, 1, 1\n",
      "Jv1UeLkc4beo, 1, 1\n",
      "8EcGmW8AXSPl, 1, 1\n",
      "uHEISY6Pnlzm, 1, 1\n",
      "AlhAMyz7XRmc, 1, 1\n",
      "jqVfgp32Kynb, 1, 1\n",
      "kkMmh1GtzDLA, 1, 1\n",
      "Oyju5jxQgUSe, 1, 1\n",
      "xGcOyShOcPRs, 1, 1\n",
      "DaveDB2gyn6A, 0, 1\n",
      "OuMuraCnt34F, 1, 1\n",
      "R5GuhuSlgOO7, 1, 1\n",
      "ZrhtdcUFpSDs, 1, 1\n",
      "UadZfjdEg7eG, 1, 1\n",
      "IUEHiLmQAqCi, 1, 1\n",
      "cRySmCadYFRO, 1, 1\n",
      "E3MvDUtJadc5, 1, 1\n",
      "dQJXfyRazknD, 1, 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "import xgboost as xgb\n",
    "from imblearn.combine import SMOTEENN\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def find_optimal_threshold_for_metric(y_true, y_prob, target_metric='sensitivity', target_value=0.90):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold that achieves a target value for a specific metric.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true: True binary labels\n",
    "        y_prob: Predicted probabilities\n",
    "        target_metric: 'sensitivity', 'specificity', 'precision', or 'npv' (negative predictive value)\n",
    "        target_value: Target value for the metric (e.g., 0.90 for 90% sensitivity)\n",
    "    \n",
    "    Returns:\n",
    "        optimal_threshold: Threshold that gets closest to target value\n",
    "        achieved_value: Actual value achieved for the target metric\n",
    "        other_metrics: Dictionary with values for other metrics at this threshold\n",
    "    \"\"\"\n",
    "    # Define a range of thresholds to try\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    \n",
    "    # Initialize variables to track the optimal threshold\n",
    "    min_distance = float('inf')\n",
    "    optimal_threshold = 0.5\n",
    "    achieved_value = 0\n",
    "    other_metrics = {}\n",
    "    \n",
    "    # Evaluate each threshold\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "        \n",
    "        # Determine the current metric value based on the target metric\n",
    "        if target_metric == 'sensitivity':\n",
    "            current_value = sensitivity\n",
    "        elif target_metric == 'specificity':\n",
    "            current_value = specificity\n",
    "        elif target_metric == 'precision':\n",
    "            current_value = precision\n",
    "        elif target_metric == 'npv':\n",
    "            current_value = npv\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown target metric: {target_metric}\")\n",
    "        \n",
    "        # Calculate distance from target value\n",
    "        distance = abs(current_value - target_value)\n",
    "        \n",
    "        # Update the optimal threshold if this is closer to the target\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            optimal_threshold = threshold\n",
    "            achieved_value = current_value\n",
    "            other_metrics = {\n",
    "                'sensitivity': sensitivity,\n",
    "                'specificity': specificity,\n",
    "                'precision': precision,\n",
    "                'npv': npv,\n",
    "                'accuracy': (tp + tn) / (tp + tn + fp + fn)\n",
    "            }\n",
    "    \n",
    "    return optimal_threshold, achieved_value, other_metrics\n",
    "\n",
    "def identify_behavioral_features(feature_names):\n",
    "    \"\"\"\n",
    "    Identify behavioral features based on their names.\n",
    "    Focuses on features that likely represent behavioral characteristics.\n",
    "    \"\"\"\n",
    "    behavioral_keywords = [\n",
    "        'SDQ', 'EHQ', 'APQ', 'behavior', 'conduct', \n",
    "        'hyperactivity', 'attention', 'emotional',\n",
    "        'social', 'peer', 'activity', 'anxiety', 'depression',\n",
    "        'impulsivity', 'externalizing', 'internalizing',\n",
    "        'difficulties', 'impact', 'generating'\n",
    "    ]\n",
    "    \n",
    "    # Identify behavioral features\n",
    "    behavioral_features = []\n",
    "    for feature in feature_names:\n",
    "        if any(keyword.lower() in feature.lower() for keyword in behavioral_keywords):\n",
    "            behavioral_features.append(feature)\n",
    "    \n",
    "    return behavioral_features\n",
    "\n",
    "def create_interaction_features(X, behavioral_features, feature_names, max_interactions=50):\n",
    "    \"\"\"\n",
    "    Create interaction terms between behavioral features.\n",
    "    \"\"\"\n",
    "    # Get indices of behavioral features\n",
    "    behavioral_indices = [feature_names.index(f) for f in behavioral_features if f in feature_names]\n",
    "    \n",
    "    # Create interaction terms\n",
    "    interaction_pairs = list(itertools.combinations(behavioral_indices, 2))\n",
    "    \n",
    "    # Limit number of interactions if needed\n",
    "    if len(interaction_pairs) > max_interactions:\n",
    "        np.random.seed(42)\n",
    "        interaction_pairs = np.random.choice(interaction_pairs, max_interactions, replace=False)\n",
    "    \n",
    "    # Create interaction terms\n",
    "    X_with_interactions = X.copy()\n",
    "    interaction_names = []\n",
    "    \n",
    "    for i, j in interaction_pairs:\n",
    "        interaction_term = X[:, i] * X[:, j]\n",
    "        X_with_interactions = np.column_stack((X_with_interactions, interaction_term))\n",
    "        interaction_names.append(f\"{feature_names[i]}*{feature_names[j]}\")\n",
    "    \n",
    "    print(f\"Created {len(interaction_names)} interaction terms between behavioral features\")\n",
    "    \n",
    "    # Create full list of feature names including interactions\n",
    "    all_feature_names = feature_names + interaction_names\n",
    "    \n",
    "    return X_with_interactions, interaction_names, all_feature_names\n",
    "\n",
    "def high_sensitivity_predictions(output_filename='optimized_thresholds_predictions_high_sensitivity.csv', test_dataset=None):\n",
    "    \"\"\"\n",
    "    Multi-outcome prediction optimized for high sensitivity.\n",
    "    \n",
    "    Parameters:\n",
    "        output_filename: Name of the file to save predictions\n",
    "        test_dataset: Test DataFrame. If None, will try to load from 'test_df_50.csv'\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results including submission DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the training dataset\n",
    "        try:\n",
    "            # First try to load the selected features dataset\n",
    "            train_df = pd.read_csv('selected_features_dual_target.csv')\n",
    "            print(\"Using the filtered features dataset for training.\")\n",
    "        except:\n",
    "            # If not available, use the original dataset\n",
    "            train_df = pd.read_csv('train_df_50.csv')\n",
    "            print(\"Using the original dataset for training.\")\n",
    "        \n",
    "        print(f\"Training data shape: {train_df.shape}\")\n",
    "        \n",
    "        # Use the provided test dataset or try to load it\n",
    "        try:\n",
    "            # First use the provided test_dataset parameter if available\n",
    "            if test_dataset is not None:\n",
    "                test_df = test_dataset\n",
    "                print(\"Using provided test dataset parameter.\")\n",
    "            # Next try to access the global test_df if it exists\n",
    "            elif 'test_df' in globals():\n",
    "                test_df = globals()['test_df']\n",
    "                print(\"Using existing global test_df variable.\")\n",
    "            # Finally try to load it from a file\n",
    "            else:\n",
    "                test_df = pd.read_csv('test_df_50.csv')\n",
    "                print(\"Loaded test_df from file.\")\n",
    "            \n",
    "            print(f\"Test data shape: {test_df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with test dataset: {e}\")\n",
    "            print(\"Please ensure test_df is defined or 'test_df_50.csv' is available.\")\n",
    "            return None\n",
    "        \n",
    "        # Extract columns\n",
    "        target_columns = [\"ADHD_Outcome\", \"Sex_F\"]\n",
    "        feature_columns = [col for col in train_df.columns if col not in target_columns and col != 'participant_id']\n",
    "        print(f\"Original number of features: {len(feature_columns)}\")\n",
    "        \n",
    "        # Make sure test data has all needed feature columns\n",
    "        missing_columns = [col for col in feature_columns if col not in test_df.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"Warning: Test data is missing these columns: {missing_columns}\")\n",
    "            feature_columns = [col for col in feature_columns if col not in missing_columns]\n",
    "        \n",
    "        # Prepare the data\n",
    "        X_train = train_df[feature_columns].values\n",
    "        y_train = train_df[target_columns].values\n",
    "        X_test = test_df[feature_columns].values if all(col in test_df.columns for col in feature_columns) else \\\n",
    "                 np.zeros((len(test_df), len(feature_columns)))\n",
    "        \n",
    "        # Check for missing values\n",
    "        train_nan_count = np.isnan(X_train).sum()\n",
    "        test_nan_count = np.isnan(X_test).sum()\n",
    "        print(f\"\\nTraining data NaN values: {train_nan_count}\")\n",
    "        print(f\"Test data NaN values: {test_nan_count}\")\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Data Preprocessing with NaN handling\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nPreprocessing data with NaN handling...\")\n",
    "        \n",
    "        # 1. Impute missing values\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_train_imputed = imputer.fit_transform(X_train)\n",
    "        X_test_imputed = imputer.transform(X_test)\n",
    "        \n",
    "        # 2. Identify behavioral features\n",
    "        behavioral_features = identify_behavioral_features(feature_columns)\n",
    "        print(f\"Identified {len(behavioral_features)} behavioral features:\")\n",
    "        print(\", \".join(behavioral_features[:10]) + (\"...\" if len(behavioral_features) > 10 else \"\"))\n",
    "        \n",
    "        # 3. Create interaction terms between behavioral features\n",
    "        X_train_with_interactions, interaction_names, all_feature_names = create_interaction_features(\n",
    "            X_train_imputed, behavioral_features, feature_columns\n",
    "        )\n",
    "        \n",
    "        X_test_with_interactions, _, _ = create_interaction_features(\n",
    "            X_test_imputed, behavioral_features, feature_columns\n",
    "        )\n",
    "        \n",
    "        # 4. Standardize all features including interactions\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_with_interactions)\n",
    "        X_test_scaled = scaler.transform(X_test_with_interactions)\n",
    "        \n",
    "        # Handle any remaining NaNs\n",
    "        if np.isnan(X_train_scaled).any():\n",
    "            print(\"Replacing remaining NaNs in training data with zeros...\")\n",
    "            X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "        \n",
    "        if np.isnan(X_test_scaled).any():\n",
    "            print(\"Replacing remaining NaNs in test data with zeros...\")\n",
    "            X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "        \n",
    "        # 5. Feature selection to reduce dimensionality\n",
    "        print(\"\\nPerforming feature selection on interaction features...\")\n",
    "        \n",
    "        # Initialize feature selectors for each target\n",
    "        selector_adhd = RFECV(\n",
    "            estimator=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            step=0.1,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        selector_sex = RFECV(\n",
    "            estimator=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            step=0.1,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Fit selectors\n",
    "        print(\"Selecting features for ADHD_Outcome...\")\n",
    "        selector_adhd.fit(X_train_scaled, y_train[:, 0])\n",
    "        \n",
    "        print(\"Selecting features for Sex_F...\")\n",
    "        selector_sex.fit(X_train_scaled, y_train[:, 1])\n",
    "        \n",
    "        # Get selected features\n",
    "        X_train_adhd_selected = selector_adhd.transform(X_train_scaled)\n",
    "        X_test_adhd_selected = selector_adhd.transform(X_test_scaled)\n",
    "        \n",
    "        X_train_sex_selected = selector_sex.transform(X_train_scaled)\n",
    "        X_test_sex_selected = selector_sex.transform(X_test_scaled)\n",
    "        \n",
    "        # Get names of selected features\n",
    "        selected_features_adhd = [all_feature_names[i] for i in np.where(selector_adhd.support_)[0]]\n",
    "        selected_features_sex = [all_feature_names[i] for i in np.where(selector_sex.support_)[0]]\n",
    "        \n",
    "        # Count behavioral interactions in selected features\n",
    "        adhd_interaction_count = sum(1 for f in selected_features_adhd if '*' in f)\n",
    "        sex_interaction_count = sum(1 for f in selected_features_sex if '*' in f)\n",
    "        \n",
    "        print(f\"Selected {len(selected_features_adhd)} features for ADHD_Outcome ({adhd_interaction_count} interactions)\")\n",
    "        print(f\"Selected {len(selected_features_sex)} features for Sex_F ({sex_interaction_count} interactions)\")\n",
    "        \n",
    "        # Split training data for validation\n",
    "        X_train_adhd_split, X_val_adhd, y_train_adhd_split, y_val_adhd = train_test_split(\n",
    "            X_train_adhd_selected, y_train[:, 0], test_size=0.2, random_state=42, stratify=y_train[:, 0]\n",
    "        )\n",
    "        \n",
    "        X_train_sex_split, X_val_sex, y_train_sex_split, y_val_sex = train_test_split(\n",
    "            X_train_sex_selected, y_train[:, 1], test_size=0.2, random_state=42, stratify=y_train[:, 1]\n",
    "        )\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Apply SMOTE-ENN For Balanced Sampling\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nApplying SMOTE-ENN for balanced sampling...\")\n",
    "        \n",
    "        # Initialize SMOTE-ENN with conservative parameters\n",
    "        smote_enn_adhd = SMOTEENN(random_state=42, sampling_strategy='auto', n_jobs=-1)\n",
    "        smote_enn_sex = SMOTEENN(random_state=42, sampling_strategy='auto', n_jobs=-1)\n",
    "        \n",
    "        # Apply SMOTE-ENN to ADHD target\n",
    "        print(\"Balancing ADHD_Outcome data...\")\n",
    "        X_adhd_resampled, y_adhd_resampled = smote_enn_adhd.fit_resample(X_train_adhd_split, y_train_adhd_split)\n",
    "        \n",
    "        # Apply SMOTE-ENN to Sex_F target\n",
    "        print(\"Balancing Sex_F data...\")\n",
    "        X_sex_resampled, y_sex_resampled = smote_enn_sex.fit_resample(X_train_sex_split, y_train_sex_split)\n",
    "        \n",
    "        # Print resampling statistics\n",
    "        print(f\"Original ADHD class distribution: {np.bincount(y_train_adhd_split)}\")\n",
    "        print(f\"Resampled ADHD class distribution: {np.bincount(y_adhd_resampled)}\")\n",
    "        print(f\"Original Sex_F class distribution: {np.bincount(y_train_sex_split)}\")\n",
    "        print(f\"Resampled Sex_F class distribution: {np.bincount(y_sex_resampled)}\")\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Train Models with Feature Interactions\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nTraining models with feature interactions...\")\n",
    "        \n",
    "        # ADHD model with XGBoost\n",
    "        print(\"Training XGBoost model for ADHD_Outcome...\")\n",
    "        xgb_adhd = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            min_child_weight=2,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            n_estimators=200,\n",
    "            random_state=42\n",
    "        )\n",
    "        xgb_adhd.fit(X_adhd_resampled, y_adhd_resampled)\n",
    "        \n",
    "        # Sex_F model with XGBoost\n",
    "        print(\"Training XGBoost model for Sex_F...\")\n",
    "        xgb_sex = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            min_child_weight=2,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            n_estimators=200,\n",
    "            random_state=42\n",
    "        )\n",
    "        xgb_sex.fit(X_sex_resampled, y_sex_resampled)\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Evaluate Models and Find High Sensitivity Thresholds\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nFinding optimal thresholds for high sensitivity...\")\n",
    "        \n",
    "        # Get predicted probabilities\n",
    "        adhd_probs = xgb_adhd.predict_proba(X_val_adhd)[:, 1]\n",
    "        sex_probs = xgb_sex.predict_proba(X_val_sex)[:, 1]\n",
    "        \n",
    "        # High sensitivity threshold (e.g., 90%)\n",
    "        adhd_sens_threshold, adhd_sens_achieved, adhd_sens_metrics = find_optimal_threshold_for_metric(\n",
    "            y_val_adhd, adhd_probs, 'sensitivity', 0.90\n",
    "        )\n",
    "        \n",
    "        # High sensitivity threshold (e.g., 90%)\n",
    "        sex_sens_threshold, sex_sens_achieved, sex_sens_metrics = find_optimal_threshold_for_metric(\n",
    "            y_val_sex, sex_probs, 'sensitivity', 0.90\n",
    "        )\n",
    "        \n",
    "        # Print threshold results\n",
    "        print(\"\\nOptimized Thresholds for High Sensitivity:\")\n",
    "        print(f\"ADHD_Outcome Threshold: {adhd_sens_threshold:.4f}\")\n",
    "        print(f\"  Sensitivity: {adhd_sens_metrics['sensitivity']:.4f}, Specificity: {adhd_sens_metrics['specificity']:.4f}\")\n",
    "        print(f\"  Accuracy: {adhd_sens_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        print(f\"Sex_F Threshold: {sex_sens_threshold:.4f}\")\n",
    "        print(f\"  Sensitivity: {sex_sens_metrics['sensitivity']:.4f}, Specificity: {sex_sens_metrics['specificity']:.4f}\")\n",
    "        print(f\"  Accuracy: {sex_sens_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        # Calculate AUC scores\n",
    "        adhd_auc = roc_auc_score(y_val_adhd, adhd_probs)\n",
    "        sex_auc = roc_auc_score(y_val_sex, sex_probs)\n",
    "        print(f\"\\nADHD_Outcome AUC: {adhd_auc:.4f}\")\n",
    "        print(f\"Sex_F AUC: {sex_auc:.4f}\")\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Visualize ROC curves with thresholds\n",
    "        # -----------------------------------------------------------------------------\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        \n",
    "        # ADHD ROC curve\n",
    "        plt.subplot(1, 2, 1)\n",
    "        fpr, tpr, thresholds = roc_curve(y_val_adhd, adhd_probs)\n",
    "        plt.plot(fpr, tpr, 'b-', label=f'AUC = {adhd_auc:.4f}')\n",
    "        \n",
    "        # Mark threshold on the curve\n",
    "        idx = np.argmin(np.abs(thresholds - adhd_sens_threshold))\n",
    "        plt.plot(fpr[idx], tpr[idx], 'o', markersize=10, label=f'High Sensitivity ({adhd_sens_threshold:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ADHD_Outcome ROC Curve with High Sensitivity Threshold')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        # Sex_F ROC curve\n",
    "        plt.subplot(1, 2, 2)\n",
    "        fpr, tpr, thresholds = roc_curve(y_val_sex, sex_probs)\n",
    "        plt.plot(fpr, tpr, 'b-', label=f'AUC = {sex_auc:.4f}')\n",
    "        \n",
    "        # Mark threshold on the curve\n",
    "        idx = np.argmin(np.abs(thresholds - sex_sens_threshold))\n",
    "        plt.plot(fpr[idx], tpr[idx], 'o', markersize=10, label=f'High Sensitivity ({sex_sens_threshold:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Sex_F ROC Curve with High Sensitivity Threshold')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('high_sensitivity_threshold.png')\n",
    "        print(\"\\nHigh sensitivity threshold plot saved to: high_sensitivity_threshold.png\")\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Retrain on Full Dataset\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nRetraining models on full dataset...\")\n",
    "        \n",
    "        # Apply SMOTE-ENN to full datasets\n",
    "        X_train_adhd_full_resampled, y_train_adhd_full_resampled = smote_enn_adhd.fit_resample(\n",
    "            X_train_adhd_selected, y_train[:, 0]\n",
    "        )\n",
    "        \n",
    "        X_train_sex_full_resampled, y_train_sex_full_resampled = smote_enn_sex.fit_resample(\n",
    "            X_train_sex_selected, y_train[:, 1]\n",
    "        )\n",
    "        \n",
    "        # Train final models\n",
    "        final_xgb_adhd = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            min_child_weight=2,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            n_estimators=300,  # Increased for final model\n",
    "            random_state=42\n",
    "        )\n",
    "        final_xgb_adhd.fit(X_train_adhd_full_resampled, y_train_adhd_full_resampled)\n",
    "        \n",
    "        final_xgb_sex = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            min_child_weight=2,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            n_estimators=300,  # Increased for final model\n",
    "            random_state=42\n",
    "        )\n",
    "        final_xgb_sex.fit(X_train_sex_full_resampled, y_train_sex_full_resampled)\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Generate Test Predictions with High Sensitivity Threshold\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nGenerating predictions for test data with high sensitivity threshold...\")\n",
    "        \n",
    "        # Generate prediction probabilities\n",
    "        test_adhd_probs = final_xgb_adhd.predict_proba(X_test_adhd_selected)[:, 1]\n",
    "        test_sex_probs = final_xgb_sex.predict_proba(X_test_sex_selected)[:, 1]\n",
    "        \n",
    "        # Apply high sensitivity thresholds\n",
    "        test_adhd_sens_preds = (test_adhd_probs >= adhd_sens_threshold).astype(int)\n",
    "        test_sex_sens_preds = (test_sex_probs >= sex_sens_threshold).astype(int)\n",
    "        \n",
    "        # Ensure participant_id is available\n",
    "        if 'participant_id' not in test_df.columns:\n",
    "            print(\"Warning: participant_id column not found in test data. Using row index as ID.\")\n",
    "            participant_ids = np.arange(1, len(test_df) + 1)\n",
    "        else:\n",
    "            participant_ids = test_df['participant_id'].values\n",
    "        \n",
    "        # Create submission DataFrame for high sensitivity threshold\n",
    "        submission_sens_df = pd.DataFrame({\n",
    "            'participant_id': participant_ids,\n",
    "            'ADHD_Outcome': test_adhd_sens_preds,\n",
    "            'Sex_F': test_sex_sens_preds\n",
    "        })\n",
    "        \n",
    "        # Create detailed DataFrame with predictions and probabilities\n",
    "        details_df = pd.DataFrame({\n",
    "            'participant_id': participant_ids,\n",
    "            'ADHD_Probability': test_adhd_probs,\n",
    "            'Sex_F_Probability': test_sex_probs,\n",
    "            'ADHD_Threshold': adhd_sens_threshold,\n",
    "            'Sex_F_Threshold': sex_sens_threshold,\n",
    "            'ADHD_Prediction': test_adhd_sens_preds,\n",
    "            'Sex_F_Prediction': test_sex_sens_preds\n",
    "        })\n",
    "        \n",
    "        # Save to CSV files\n",
    "        submission_sens_df.to_csv(output_filename, index=False)\n",
    "        details_df.to_csv(output_filename.replace('.csv', '_details.csv'), index=False)\n",
    "        \n",
    "        print(f\"\\nHigh sensitivity predictions saved to: {output_filename}\")\n",
    "        print(f\"Detailed prediction data saved to: {output_filename.replace('.csv', '_details.csv')}\")\n",
    "        \n",
    "        # Print formatted outputs\n",
    "        print(\"\\nFormatted predictions (High Sensitivity Threshold):\")\n",
    "        print(\"participant_id,ADHD_Outcome,Sex_F\")\n",
    "        for _, row in submission_sens_df.iterrows():\n",
    "            print(f\"{row['participant_id']}, {row['ADHD_Outcome']}, {row['Sex_F']}\")\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Return Results\n",
    "        # -----------------------------------------------------------------------------\n",
    "        return {\n",
    "            'adhd_threshold': {\n",
    "                'value': adhd_sens_threshold,\n",
    "                'metrics': adhd_sens_metrics\n",
    "            },\n",
    "            'sex_threshold': {\n",
    "                'value': sex_sens_threshold,\n",
    "                'metrics': sex_sens_metrics\n",
    "            },\n",
    "            'submission': submission_sens_df,\n",
    "            'details': details_df,\n",
    "            'auc_scores': {\n",
    "                'adhd': adhd_auc,\n",
    "                'sex': sex_auc\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Execute the function if run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Try to access the existing test_df variable if available\n",
    "    if 'test_df' in globals():\n",
    "        results = high_sensitivity_predictions(test_dataset=test_df)\n",
    "    else:\n",
    "        results = high_sensitivity_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the filtered features dataset for training.\n",
      "Training data shape: (1213, 17)\n",
      "Using provided test dataset parameter.\n",
      "Test data shape: (304, 19928)\n",
      "Original number of features: 15\n",
      "\n",
      "Training data NaN values: 0\n",
      "Test data NaN values: 285\n",
      "\n",
      "Preprocessing data with NaN handling...\n",
      "Identified 10 behavioral features:\n",
      "SDQ_SDQ_Hyperactivity, SDQ_SDQ_Externalizing, SDQ_SDQ_Difficulties_Total, SDQ_SDQ_Generating_Impact, SDQ_SDQ_Conduct_Problems, SDQ_SDQ_Internalizing, SDQ_SDQ_Emotional_Problems, SDQ_SDQ_Prosocial, SDQ_SDQ_Peer_Problems, APQ_P_APQ_P_OPD\n",
      "Created 45 interaction terms between behavioral features\n",
      "Created 45 interaction terms between behavioral features\n",
      "\n",
      "Performing feature selection on interaction features...\n",
      "Selecting features for ADHD_Outcome...\n",
      "Selecting features for Sex_F...\n",
      "Selected 12 features for ADHD_Outcome (7 interactions)\n",
      "Selected 18 features for Sex_F (14 interactions)\n",
      "\n",
      "Identifying subgroups for ADHD prediction...\n",
      "Subgroup 1: 250 samples (20.6%)\n",
      "Subgroup 2: 494 samples (40.7%)\n",
      "Subgroup 3: 469 samples (38.7%)\n",
      "\n",
      "Identifying subgroups for Sex_F prediction...\n",
      "Subgroup 1: 501 samples (41.3%)\n",
      "Subgroup 2: 274 samples (22.6%)\n",
      "Subgroup 3: 438 samples (36.1%)\n",
      "\n",
      "Training ADHD models for each subgroup...\n",
      "\n",
      "Processing ADHD subgroup 1...\n",
      "  Training samples: 186, Validation samples: 64\n",
      "  Original class distribution: [  7 179]\n",
      "  Resampled class distribution: [179 135]\n",
      "  Optimized threshold: 0.3600\n",
      "  Sensitivity: 0.8983, Specificity: 0.0000, Accuracy: 0.8281\n",
      "\n",
      "Processing ADHD subgroup 2...\n",
      "  Training samples: 410, Validation samples: 84\n",
      "  Original class distribution: [238 172]\n",
      "  Resampled class distribution: [75 82]\n",
      "  Optimized threshold: 0.0200\n",
      "  Sensitivity: 0.9032, Specificity: 0.1887, Accuracy: 0.4524\n",
      "\n",
      "Processing ADHD subgroup 3...\n",
      "  Training samples: 374, Validation samples: 95\n",
      "  Original class distribution: [ 60 314]\n",
      "  Resampled class distribution: [293 163]\n",
      "  Optimized threshold: 0.1700\n",
      "  Sensitivity: 0.8947, Specificity: 0.3158, Accuracy: 0.7789\n",
      "\n",
      "Training Sex_F models for each subgroup...\n",
      "\n",
      "Processing Sex_F subgroup 1...\n",
      "  Training samples: 399, Validation samples: 102\n",
      "  Original class distribution: [277 122]\n",
      "  Resampled class distribution: [ 78 185]\n",
      "  Optimized threshold: 0.1500\n",
      "  Sensitivity: 0.9167, Specificity: 0.0513, Accuracy: 0.2549\n",
      "\n",
      "Processing Sex_F subgroup 2...\n",
      "  Training samples: 213, Validation samples: 61\n",
      "  Original class distribution: [142  71]\n",
      "  Resampled class distribution: [47 99]\n",
      "  Optimized threshold: 0.0400\n",
      "  Sensitivity: 0.8846, Specificity: 0.0857, Accuracy: 0.4262\n",
      "\n",
      "Processing Sex_F subgroup 3...\n",
      "  Training samples: 358, Validation samples: 80\n",
      "  Original class distribution: [218 140]\n",
      "  Resampled class distribution: [ 59 107]\n",
      "  Optimized threshold: 0.0800\n",
      "  Sensitivity: 0.9091, Specificity: 0.1702, Accuracy: 0.4750\n",
      "\n",
      "Retraining final models...\n",
      "Retraining ADHD model for subgroup 1...\n",
      "Retraining ADHD model for subgroup 2...\n",
      "Retraining ADHD model for subgroup 3...\n",
      "Retraining Sex_F model for subgroup 1...\n",
      "Retraining Sex_F model for subgroup 2...\n",
      "Retraining Sex_F model for subgroup 3...\n",
      "\n",
      "Generating predictions for test data with subgroup-specific thresholds...\n",
      "ADHD Subgroup 1: Applied threshold 0.3600 to 281 samples\n",
      "ADHD Subgroup 2: Applied threshold 0.0200 to 12 samples\n",
      "ADHD Subgroup 3: Applied threshold 0.1700 to 11 samples\n",
      "Sex_F Subgroup 1: Applied threshold 0.1500 to 10 samples\n",
      "Sex_F Subgroup 2: Applied threshold 0.0400 to 294 samples\n",
      "\n",
      "Predictions with subgroup-specific thresholds saved to: multi_outcome_subgroups.csv\n",
      "Detailed prediction data saved to: multi_outcome_subgroups_details.csv\n",
      "ADHD subgroup information saved to: multi_outcome_subgroups_adhd_subgroups.csv\n",
      "Sex_F subgroup information saved to: multi_outcome_subgroups_sex_subgroups.csv\n",
      "\n",
      "Formatted predictions with subgroup-specific thresholds:\n",
      "participant_id,ADHD_Outcome,Sex_F\n",
      "Cfwaf5FX7jWK, 1, 1\n",
      "vhGrzmvA3Hjq, 1, 1\n",
      "ULliyEXjy4OV, 1, 1\n",
      "LZfeAb1xMtql, 1, 1\n",
      "EnFOUv0YK1RG, 1, 1\n",
      "3VbkvJ22j9Fu, 0, 1\n",
      "PRKZcnOgqcuk, 1, 1\n",
      "DuVUuyMZi5qV, 1, 1\n",
      "uM4etVLZrgMg, 1, 1\n",
      "BpzyExrET5ta, 1, 1\n",
      "sAqeb6F4lz97, 1, 1\n",
      "u7XOOvHirIx7, 1, 1\n",
      "aEPm4bEQvbYi, 1, 1\n",
      "Fj9A5PWsIWKT, 1, 1\n",
      "19mb5yGJigtw, 1, 0\n",
      "v1nMpCoLGU0V, 1, 1\n",
      "hRPuz4zpsEbw, 1, 1\n",
      "mT8A6xa1O4Ro, 1, 1\n",
      "4QBTjDoVpVt6, 1, 1\n",
      "0X2H4LroxZcw, 1, 1\n",
      "9CH7UxXuznUa, 1, 1\n",
      "nU73zzjTnr4A, 1, 1\n",
      "uEZHGukIUQ0k, 1, 1\n",
      "jCzQwkpfgZyQ, 1, 1\n",
      "Ljvrs76QJuI5, 1, 1\n",
      "IbF3zW0Wbx4Q, 1, 1\n",
      "UHnGiDNksa0x, 1, 1\n",
      "yYjiJsx8PM48, 1, 1\n",
      "1j28gfEoCQ3o, 1, 1\n",
      "dC5XvD5A3tqo, 1, 1\n",
      "5irK4m6otW7R, 1, 1\n",
      "88IME13c7xDB, 1, 1\n",
      "GYQvyFy7QF7z, 1, 1\n",
      "rZ4Djyg4w7Yv, 1, 1\n",
      "g7OzSuPQs2wx, 0, 1\n",
      "7gx6bnmZrxKv, 1, 1\n",
      "sslRc6ajaOkD, 1, 1\n",
      "h5xmGEy5uNA9, 1, 1\n",
      "sQaDS15dgJw7, 1, 1\n",
      "erkdzShJ7zHD, 1, 1\n",
      "xb3e1IzlY1QV, 1, 1\n",
      "hAY3GGKYCKNz, 1, 1\n",
      "Qf7YnjK9A9Nr, 1, 1\n",
      "pJXKagbu6k5J, 1, 1\n",
      "GusOn8clPEcS, 1, 1\n",
      "HynLNt7eOUu6, 0, 1\n",
      "VHaWyqk3brmj, 1, 1\n",
      "XsnFuC5RuxEj, 1, 1\n",
      "fJ18nx0flUWU, 1, 1\n",
      "z0TcjaAHc8af, 0, 1\n",
      "cwhzTO0Vu9fs, 0, 1\n",
      "FJ14ni1wdpx0, 1, 1\n",
      "LbvK4T5h6Bgg, 1, 1\n",
      "g8nC5onuX4Iu, 1, 1\n",
      "X8fHsDpoMCrc, 1, 1\n",
      "9MLL7pYQEsHg, 1, 1\n",
      "Rl4ewZ2JsYiu, 1, 1\n",
      "NPqPE9t9ANPY, 1, 1\n",
      "xdNPzLAsxshh, 1, 0\n",
      "Fkys1lBZ0EYl, 1, 1\n",
      "9bB7cb8GIt55, 1, 1\n",
      "S2aUm7iSCh8K, 1, 1\n",
      "uMXsb9zvFhZG, 1, 1\n",
      "WswtU2xjkwrJ, 1, 1\n",
      "NUD1SQ26nGwx, 1, 1\n",
      "1lqQa6Bvsvgo, 1, 1\n",
      "nLIxzOqeY0F8, 1, 1\n",
      "ZnpZwNyveSC1, 1, 1\n",
      "g065FaS0cDJw, 1, 1\n",
      "5nPxL5XWeWqT, 1, 1\n",
      "PXgJvd8UZ9fe, 1, 1\n",
      "bRHXqarRnTOl, 1, 1\n",
      "iC4lUrNmd76W, 1, 1\n",
      "e5PO7MIzpSKp, 1, 1\n",
      "iQ5WKoVa0Oe8, 0, 1\n",
      "1zYwUOsWtWUO, 1, 1\n",
      "9dIzgZgU0t2O, 1, 1\n",
      "FZZFnxIITvIb, 1, 1\n",
      "UZ4wZJktSjXM, 1, 1\n",
      "47cpL5bSIaes, 1, 1\n",
      "cD8B0lz9W1Cc, 1, 1\n",
      "RBUqOe8h6Rjz, 1, 1\n",
      "xMcjmmscXHRg, 1, 1\n",
      "zIkbsyNlTbCK, 1, 0\n",
      "eqXWWdeNFQoH, 1, 1\n",
      "FUBvB3niWLlN, 1, 1\n",
      "RZKV9tFLkC9q, 1, 1\n",
      "YX2nejjQrjTE, 0, 1\n",
      "9uCWNQLzILyS, 1, 1\n",
      "PJvfoHAcsFop, 1, 1\n",
      "rsQPeuxeuzFN, 0, 1\n",
      "xgRkRXFj22eG, 1, 1\n",
      "NSvVb4rAbXKU, 1, 1\n",
      "rY7ztwsrfyfe, 1, 1\n",
      "0idudG3MZeOR, 1, 1\n",
      "tbZrR9R4zdPW, 1, 1\n",
      "mmW5cD4mDCyK, 1, 1\n",
      "FvnoZ1q1rX2c, 1, 1\n",
      "rIE98UuGpsXN, 1, 1\n",
      "a4NfOjK4u0pw, 1, 1\n",
      "x0tFPjGEtTDo, 1, 1\n",
      "Lf1aRmgJMGzn, 1, 1\n",
      "qxDaOMmN2fGr, 1, 1\n",
      "jZz3FS9Lxw7Y, 1, 1\n",
      "EQdMyNMDvWuv, 1, 1\n",
      "fpbYYqEmKmBP, 1, 1\n",
      "Ljl0uwPY3cHC, 1, 1\n",
      "h5uHyT7ZsggG, 1, 1\n",
      "REHeZZWpqbXA, 1, 1\n",
      "WDaVjmgqDtdH, 1, 1\n",
      "JPbjWX5WRMo5, 1, 1\n",
      "m4i3mVopmQND, 1, 1\n",
      "8js31yKXtVtT, 1, 1\n",
      "ThzfJlzfC5zm, 1, 1\n",
      "PKmY55L3l7nh, 1, 1\n",
      "EjMbGKIXc6xh, 1, 1\n",
      "hRtu2jZGjsqu, 1, 1\n",
      "wE08jf7axl4G, 1, 1\n",
      "oFqFWjZvQpdq, 1, 1\n",
      "rZRMMWCz9o54, 1, 1\n",
      "7bH7tOSH8tyL, 1, 1\n",
      "VsAjWDqZH10d, 1, 1\n",
      "mca5wy8JcazG, 1, 1\n",
      "LsErFKyD0Amx, 1, 1\n",
      "7v5DsWe80ek1, 1, 0\n",
      "idllOUP39Yoy, 1, 1\n",
      "Wm8vHtUOTSdK, 1, 1\n",
      "lIo1EopEayvT, 1, 1\n",
      "ceMWzYEKDxGS, 1, 1\n",
      "RfNlGWXzHH3K, 1, 1\n",
      "nLaCfgOfeeux, 1, 1\n",
      "hHbDtQpct0sM, 1, 1\n",
      "xctrrQN3v50J, 1, 1\n",
      "sdJvoGXQsxzG, 1, 1\n",
      "na1higV3BYix, 0, 1\n",
      "iUhm6elzNZnR, 1, 1\n",
      "IDLPcayOzo7t, 1, 1\n",
      "Z0CZjkr8SDlo, 1, 1\n",
      "ddE1W1SfgV7E, 1, 1\n",
      "duMJcIFRvvUn, 1, 1\n",
      "Ya9QbWu9Oyj7, 1, 1\n",
      "aJeuvuedrbei, 1, 1\n",
      "rUXfpz4ZIVqs, 1, 1\n",
      "66ATazbm1n2H, 1, 1\n",
      "gf8iAJH7Y6LW, 0, 1\n",
      "T3jFzkEFn2lB, 1, 1\n",
      "eAEV7RHPm4gn, 1, 1\n",
      "MOjMYkTSkCT0, 1, 1\n",
      "fLsk0v5A9QWD, 1, 1\n",
      "e4u1878wt5Vu, 1, 1\n",
      "ZssVYalOAWOn, 1, 1\n",
      "eFGeJZyaYTfW, 1, 1\n",
      "DgwxZPoFWSFV, 1, 1\n",
      "vCYoh5kuBxBn, 1, 1\n",
      "DkwrzlcjCXzl, 1, 1\n",
      "pQk5LK9WWNlU, 1, 1\n",
      "4TfoOtVqQGIS, 1, 1\n",
      "xm87i9BWm3LH, 1, 1\n",
      "HfAWB7M67jZ7, 1, 1\n",
      "CHEK30GPB53F, 1, 1\n",
      "0ImS6uhE3Ie9, 1, 1\n",
      "x2HGm8Cdw3pH, 1, 1\n",
      "rUhntCqf0veY, 1, 1\n",
      "lviw20KdXmyz, 1, 1\n",
      "EUN1xz5MmK3h, 1, 1\n",
      "JHgSIO5g9kyN, 1, 1\n",
      "HuavjkfJT3Ra, 1, 1\n",
      "jRKvisBZEvMV, 1, 1\n",
      "T7MMp5ZjZIP7, 1, 1\n",
      "7Y5dXDvM5JlW, 1, 1\n",
      "xsEm3scLKQqx, 1, 1\n",
      "CZ6cLlIFT8C7, 1, 1\n",
      "Nm0QSvXNt8IL, 1, 1\n",
      "ZVJtXjkAAp8k, 1, 1\n",
      "kxJ2iDDo7le7, 0, 1\n",
      "KlEGztcVpqQM, 1, 1\n",
      "SEpZVWxwPwzJ, 1, 1\n",
      "3ex9wBx3bXzf, 1, 1\n",
      "GtKTU9RdYH88, 1, 1\n",
      "pXjemmrXv9XU, 1, 1\n",
      "G4HH3C3252g1, 1, 1\n",
      "i103EbS97ZlA, 1, 1\n",
      "V62GcAZSGGHt, 1, 1\n",
      "7uXcG7moAMys, 1, 1\n",
      "MGSeDY5xsLcH, 1, 1\n",
      "HEv7u3wwBUID, 1, 1\n",
      "0joIpvJZmHlM, 1, 1\n",
      "R1WkyITqb6j5, 1, 1\n",
      "y1YkOqsv0518, 1, 1\n",
      "8uNQKfpBZKGT, 1, 1\n",
      "FMKnba82Blol, 1, 1\n",
      "JOL7WOOECWqz, 1, 1\n",
      "c4XMogBDs3JV, 1, 1\n",
      "Aqr7TbYLogDt, 1, 1\n",
      "cWVOYIyTGoPW, 1, 1\n",
      "5F9KuchRWc28, 1, 1\n",
      "GpBWQZEEB8Na, 1, 1\n",
      "1nuCB3iu56Ao, 1, 1\n",
      "tcKZk7TJNjXP, 0, 1\n",
      "Bf8xkS0DgEdq, 1, 1\n",
      "UOohdAfiU2WX, 1, 1\n",
      "CdwfVAJW6U21, 1, 1\n",
      "K3TeYDSt1D69, 1, 1\n",
      "7UT8iirSGhRL, 1, 1\n",
      "q4kyWzfZIqDG, 1, 1\n",
      "06HFIpqKfXy9, 1, 1\n",
      "ZjFv6ztsCBLY, 1, 1\n",
      "rpLRzoX7qzUA, 1, 1\n",
      "tgxIaIPsvpIG, 0, 1\n",
      "iq3Izns35R7e, 1, 1\n",
      "rcUdzoimoCO3, 1, 1\n",
      "RlH1HdX1zOXp, 1, 1\n",
      "sPSXo6gaMyoT, 1, 1\n",
      "i4PoyNNskpN2, 1, 1\n",
      "NppPTQNMYrDr, 1, 1\n",
      "b2MRYJQHtN4Q, 1, 1\n",
      "Z1USdfsVnnjw, 1, 1\n",
      "Cm1JesyqVvvU, 1, 1\n",
      "wfHMTWwtSFnV, 1, 1\n",
      "ZH3fhLHNBy2N, 1, 1\n",
      "zHoI2y6ghT8f, 1, 1\n",
      "5gde2X56TEaV, 1, 1\n",
      "h1NsELdECZtN, 1, 1\n",
      "WVyjBIVNp84k, 1, 1\n",
      "I7wdCrc41LkV, 1, 1\n",
      "dYeoDCtqrZOk, 1, 1\n",
      "gTo2ZwRYwLIM, 1, 1\n",
      "cS46aS2dNkWt, 1, 1\n",
      "0Dua0TUw4sNZ, 1, 1\n",
      "Bct9jCffkwTU, 1, 1\n",
      "0wdp92SlZ6os, 1, 1\n",
      "3ymvGMbsXkDa, 1, 1\n",
      "3CHeLp88N9PU, 1, 1\n",
      "3GuHHSzexdrD, 1, 1\n",
      "BxG4CGNyBthY, 1, 1\n",
      "r1kJWdiLnlzB, 1, 1\n",
      "PHcnlHPVth3A, 1, 1\n",
      "JjO5xmUVZlHV, 1, 1\n",
      "uhrbzFdVttif, 1, 1\n",
      "vFUC44u3e6yc, 1, 1\n",
      "KK1MoDOaknzz, 1, 1\n",
      "xeGDqEHl50Pe, 1, 1\n",
      "MbnL2SsZ3SfN, 1, 1\n",
      "lzsnunuLD5E9, 1, 1\n",
      "ypPOBnAE3X5L, 1, 1\n",
      "t6Yc857Xm0G1, 1, 1\n",
      "IFfLWRuXYCud, 1, 1\n",
      "mMKlS7Xx90To, 1, 1\n",
      "4SP0VjzBYTnA, 1, 1\n",
      "6g9qhyTboWDX, 1, 1\n",
      "zoCHkxMZDLeD, 1, 1\n",
      "J6jcTOKF9FKI, 1, 1\n",
      "knYPTVqlhOOe, 1, 1\n",
      "6mGSjnkluhCm, 1, 1\n",
      "CHK7PetkESpw, 1, 1\n",
      "KOhyaYYWH4J7, 1, 1\n",
      "0VHL9SCh2TfC, 1, 1\n",
      "kA6qrwNv3TVN, 1, 1\n",
      "mby0aqc4xfJt, 0, 1\n",
      "ukPFRpacqtjF, 1, 1\n",
      "JDCneyZ2d8oS, 1, 1\n",
      "frwFik2vzPpk, 1, 1\n",
      "MdR8Vu1UGsUh, 1, 1\n",
      "fQDGE3yvi8JG, 1, 1\n",
      "cMG1xz902zCv, 1, 1\n",
      "czseCZwxGu9b, 1, 1\n",
      "EqjgIpp1uQFT, 1, 1\n",
      "SU2iR4dZt71Q, 1, 1\n",
      "Y8y8VL92UXUp, 1, 1\n",
      "iIM7qDzkFHrK, 1, 1\n",
      "tcvQwlcXDrjM, 1, 1\n",
      "E5WW2AJI3cmY, 1, 1\n",
      "so28UOwqRGcv, 0, 1\n",
      "JhsrI2yTZUCS, 1, 1\n",
      "pVZ5eyvBxRXh, 1, 1\n",
      "8OuOUWiYizQT, 1, 1\n",
      "22mg5880yUSV, 1, 1\n",
      "OCfNYCcRM3dw, 1, 1\n",
      "PDtAgNUCR1F1, 1, 1\n",
      "nJJWVTrUPKHh, 1, 1\n",
      "8GLRwVrATqDq, 1, 1\n",
      "geK1iR863siE, 1, 1\n",
      "9OsyiuTB9ARL, 1, 1\n",
      "ZoX0gx0mL2fe, 1, 1\n",
      "7U96jnm3G0nL, 1, 1\n",
      "8RcAlHO2Z7Z5, 1, 1\n",
      "Il8Z3DuXaX9D, 1, 1\n",
      "Jv1UeLkc4beo, 1, 1\n",
      "8EcGmW8AXSPl, 1, 1\n",
      "uHEISY6Pnlzm, 1, 1\n",
      "AlhAMyz7XRmc, 1, 1\n",
      "jqVfgp32Kynb, 1, 1\n",
      "kkMmh1GtzDLA, 1, 1\n",
      "Oyju5jxQgUSe, 1, 1\n",
      "xGcOyShOcPRs, 1, 1\n",
      "DaveDB2gyn6A, 0, 1\n",
      "OuMuraCnt34F, 1, 1\n",
      "R5GuhuSlgOO7, 1, 1\n",
      "ZrhtdcUFpSDs, 1, 1\n",
      "UadZfjdEg7eG, 1, 1\n",
      "IUEHiLmQAqCi, 1, 1\n",
      "cRySmCadYFRO, 1, 1\n",
      "E3MvDUtJadc5, 1, 1\n",
      "dQJXfyRazknD, 1, 1\n",
      "\n",
      "Subgroup-specific thresholds for ADHD prediction:\n",
      "Subgroup 1: Threshold = 0.3600, Sensitivity = 0.8983, Specificity = 0.0000\n",
      "Subgroup 2: Threshold = 0.0200, Sensitivity = 0.9032, Specificity = 0.1887\n",
      "Subgroup 3: Threshold = 0.1700, Sensitivity = 0.8947, Specificity = 0.3158\n",
      "\n",
      "Subgroup-specific thresholds for Sex_F prediction:\n",
      "Subgroup 1: Threshold = 0.1500, Sensitivity = 0.9167, Specificity = 0.0513\n",
      "Subgroup 2: Threshold = 0.0400, Sensitivity = 0.8846, Specificity = 0.0857\n",
      "Subgroup 3: Threshold = 0.0800, Sensitivity = 0.9091, Specificity = 0.1702\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "from imblearn.combine import SMOTEENN\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def find_optimal_threshold_for_metric(y_true, y_prob, target_metric='sensitivity', target_value=0.90):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold that achieves a target value for a specific metric.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true: True binary labels\n",
    "        y_prob: Predicted probabilities\n",
    "        target_metric: 'sensitivity', 'specificity', 'precision', or 'npv' (negative predictive value)\n",
    "        target_value: Target value for the metric (e.g., 0.90 for 90% sensitivity)\n",
    "    \n",
    "    Returns:\n",
    "        optimal_threshold: Threshold that gets closest to target value\n",
    "        achieved_value: Actual value achieved for the target metric\n",
    "        other_metrics: Dictionary with values for other metrics at this threshold\n",
    "    \"\"\"\n",
    "    # Define a range of thresholds to try\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    \n",
    "    # Initialize variables to track the optimal threshold\n",
    "    min_distance = float('inf')\n",
    "    optimal_threshold = 0.5\n",
    "    achieved_value = 0\n",
    "    other_metrics = {}\n",
    "    \n",
    "    # Evaluate each threshold\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "        \n",
    "        # Determine the current metric value based on the target metric\n",
    "        if target_metric == 'sensitivity':\n",
    "            current_value = sensitivity\n",
    "        elif target_metric == 'specificity':\n",
    "            current_value = specificity\n",
    "        elif target_metric == 'precision':\n",
    "            current_value = precision\n",
    "        elif target_metric == 'npv':\n",
    "            current_value = npv\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown target metric: {target_metric}\")\n",
    "        \n",
    "        # Calculate distance from target value\n",
    "        distance = abs(current_value - target_value)\n",
    "        \n",
    "        # Update the optimal threshold if this is closer to the target\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            optimal_threshold = threshold\n",
    "            achieved_value = current_value\n",
    "            other_metrics = {\n",
    "                'sensitivity': sensitivity,\n",
    "                'specificity': specificity,\n",
    "                'precision': precision,\n",
    "                'npv': npv,\n",
    "                'accuracy': (tp + tn) / (tp + tn + fp + fn)\n",
    "            }\n",
    "    \n",
    "    return optimal_threshold, achieved_value, other_metrics\n",
    "\n",
    "def identify_behavioral_features(feature_names):\n",
    "    \"\"\"\n",
    "    Identify behavioral features based on their names.\n",
    "    Focuses on features that likely represent behavioral characteristics.\n",
    "    \"\"\"\n",
    "    behavioral_keywords = [\n",
    "        'SDQ', 'EHQ', 'APQ', 'behavior', 'conduct', \n",
    "        'hyperactivity', 'attention', 'emotional',\n",
    "        'social', 'peer', 'activity', 'anxiety', 'depression',\n",
    "        'impulsivity', 'externalizing', 'internalizing',\n",
    "        'difficulties', 'impact', 'generating'\n",
    "    ]\n",
    "    \n",
    "    # Identify behavioral features\n",
    "    behavioral_features = []\n",
    "    for feature in feature_names:\n",
    "        if any(keyword.lower() in feature.lower() for keyword in behavioral_keywords):\n",
    "            behavioral_features.append(feature)\n",
    "    \n",
    "    return behavioral_features\n",
    "\n",
    "def create_interaction_features(X, behavioral_features, feature_names, max_interactions=50):\n",
    "    \"\"\"\n",
    "    Create interaction terms between behavioral features.\n",
    "    \"\"\"\n",
    "    # Get indices of behavioral features\n",
    "    behavioral_indices = [feature_names.index(f) for f in behavioral_features if f in feature_names]\n",
    "    \n",
    "    # Create interaction terms\n",
    "    interaction_pairs = list(itertools.combinations(behavioral_indices, 2))\n",
    "    \n",
    "    # Limit number of interactions if needed\n",
    "    if len(interaction_pairs) > max_interactions:\n",
    "        np.random.seed(42)\n",
    "        interaction_pairs = np.random.choice(interaction_pairs, max_interactions, replace=False)\n",
    "    \n",
    "    # Create interaction terms\n",
    "    X_with_interactions = X.copy()\n",
    "    interaction_names = []\n",
    "    \n",
    "    for i, j in interaction_pairs:\n",
    "        interaction_term = X[:, i] * X[:, j]\n",
    "        X_with_interactions = np.column_stack((X_with_interactions, interaction_term))\n",
    "        interaction_names.append(f\"{feature_names[i]}*{feature_names[j]}\")\n",
    "    \n",
    "    print(f\"Created {len(interaction_names)} interaction terms between behavioral features\")\n",
    "    \n",
    "    # Create full list of feature names including interactions\n",
    "    all_feature_names = feature_names + interaction_names\n",
    "    \n",
    "    return X_with_interactions, interaction_names, all_feature_names\n",
    "\n",
    "def identify_subgroups(X, n_clusters=3):\n",
    "    \"\"\"\n",
    "    Identify subgroups within the data using KMeans clustering.\n",
    "    \n",
    "    Parameters:\n",
    "        X: Feature matrix\n",
    "        n_clusters: Number of clusters/subgroups to identify\n",
    "        \n",
    "    Returns:\n",
    "        subgroup_labels: Cluster assignments for each sample\n",
    "    \"\"\"\n",
    "    # Initialize KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    \n",
    "    # Fit and get cluster assignments\n",
    "    subgroup_labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Print cluster sizes\n",
    "    unique, counts = np.unique(subgroup_labels, return_counts=True)\n",
    "    for i, (u, c) in enumerate(zip(unique, counts)):\n",
    "        print(f\"Subgroup {i+1}: {c} samples ({c/len(subgroup_labels)*100:.1f}%)\")\n",
    "    \n",
    "    return subgroup_labels, kmeans\n",
    "\n",
    "def multi_outcome_predictions_with_subgroups(output_filename='multi_outcome_subgroups.csv', test_dataset=None, n_subgroups=3):\n",
    "    \"\"\"\n",
    "    Multi-outcome prediction (ADHD_Outcome and Sex_F) with differential thresholds by subgroup.\n",
    "    \n",
    "    Parameters:\n",
    "        output_filename: Name of the file to save predictions\n",
    "        test_dataset: Test DataFrame. If None, will try to load from 'test_df_50.csv'\n",
    "        n_subgroups: Number of subgroups to identify\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results including submission DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the training dataset\n",
    "        try:\n",
    "            # First try to load the selected features dataset\n",
    "            train_df = pd.read_csv('selected_features_dual_target.csv')\n",
    "            print(\"Using the filtered features dataset for training.\")\n",
    "        except:\n",
    "            # If not available, use the original dataset\n",
    "            train_df = pd.read_csv('train_df_50.csv')\n",
    "            print(\"Using the original dataset for training.\")\n",
    "        \n",
    "        print(f\"Training data shape: {train_df.shape}\")\n",
    "        \n",
    "        # Use the provided test dataset or try to load it\n",
    "        try:\n",
    "            # First use the provided test_dataset parameter if available\n",
    "            if test_dataset is not None:\n",
    "                test_df = test_dataset\n",
    "                print(\"Using provided test dataset parameter.\")\n",
    "            # Next try to access the global test_df if it exists\n",
    "            elif 'test_df' in globals():\n",
    "                test_df = globals()['test_df']\n",
    "                print(\"Using existing global test_df variable.\")\n",
    "            # Finally try to load it from a file\n",
    "            else:\n",
    "                test_df = pd.read_csv('test_df_50.csv')\n",
    "                print(\"Loaded test_df from file.\")\n",
    "            \n",
    "            print(f\"Test data shape: {test_df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with test dataset: {e}\")\n",
    "            print(\"Please ensure test_df is defined or 'test_df_50.csv' is available.\")\n",
    "            return None\n",
    "        \n",
    "        # Extract columns\n",
    "        target_columns = [\"ADHD_Outcome\", \"Sex_F\"]\n",
    "        feature_columns = [col for col in train_df.columns if col not in target_columns and col != 'participant_id']\n",
    "        print(f\"Original number of features: {len(feature_columns)}\")\n",
    "        \n",
    "        # Make sure test data has all needed feature columns\n",
    "        missing_columns = [col for col in feature_columns if col not in test_df.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"Warning: Test data is missing these columns: {missing_columns}\")\n",
    "            feature_columns = [col for col in feature_columns if col not in missing_columns]\n",
    "        \n",
    "        # Prepare the data\n",
    "        X_train = train_df[feature_columns].values\n",
    "        y_train = train_df[target_columns].values\n",
    "        X_test = test_df[feature_columns].values if all(col in test_df.columns for col in feature_columns) else \\\n",
    "                 np.zeros((len(test_df), len(feature_columns)))\n",
    "        \n",
    "        # Check for missing values\n",
    "        train_nan_count = np.isnan(X_train).sum()\n",
    "        test_nan_count = np.isnan(X_test).sum()\n",
    "        print(f\"\\nTraining data NaN values: {train_nan_count}\")\n",
    "        print(f\"Test data NaN values: {test_nan_count}\")\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Data Preprocessing with NaN handling\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nPreprocessing data with NaN handling...\")\n",
    "        \n",
    "        # 1. Impute missing values\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_train_imputed = imputer.fit_transform(X_train)\n",
    "        X_test_imputed = imputer.transform(X_test)\n",
    "        \n",
    "        # 2. Identify behavioral features\n",
    "        behavioral_features = identify_behavioral_features(feature_columns)\n",
    "        print(f\"Identified {len(behavioral_features)} behavioral features:\")\n",
    "        print(\", \".join(behavioral_features[:10]) + (\"...\" if len(behavioral_features) > 10 else \"\"))\n",
    "        \n",
    "        # 3. Create interaction terms between behavioral features\n",
    "        X_train_with_interactions, interaction_names, all_feature_names = create_interaction_features(\n",
    "            X_train_imputed, behavioral_features, feature_columns\n",
    "        )\n",
    "        \n",
    "        X_test_with_interactions, _, _ = create_interaction_features(\n",
    "            X_test_imputed, behavioral_features, feature_columns\n",
    "        )\n",
    "        \n",
    "        # 4. Standardize all features including interactions\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_with_interactions)\n",
    "        X_test_scaled = scaler.transform(X_test_with_interactions)\n",
    "        \n",
    "        # Handle any remaining NaNs\n",
    "        if np.isnan(X_train_scaled).any():\n",
    "            print(\"Replacing remaining NaNs in training data with zeros...\")\n",
    "            X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "        \n",
    "        if np.isnan(X_test_scaled).any():\n",
    "            print(\"Replacing remaining NaNs in test data with zeros...\")\n",
    "            X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "        \n",
    "        # 5. Feature selection to reduce dimensionality\n",
    "        print(\"\\nPerforming feature selection on interaction features...\")\n",
    "        \n",
    "        # Initialize feature selectors for each target\n",
    "        selector_adhd = RFECV(\n",
    "            estimator=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            step=0.1,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        selector_sex = RFECV(\n",
    "            estimator=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            step=0.1,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Fit selectors\n",
    "        print(\"Selecting features for ADHD_Outcome...\")\n",
    "        selector_adhd.fit(X_train_scaled, y_train[:, 0])\n",
    "        \n",
    "        print(\"Selecting features for Sex_F...\")\n",
    "        selector_sex.fit(X_train_scaled, y_train[:, 1])\n",
    "        \n",
    "        # Get selected features\n",
    "        X_train_adhd_selected = selector_adhd.transform(X_train_scaled)\n",
    "        X_test_adhd_selected = selector_adhd.transform(X_test_scaled)\n",
    "        \n",
    "        X_train_sex_selected = selector_sex.transform(X_train_scaled)\n",
    "        X_test_sex_selected = selector_sex.transform(X_test_scaled)\n",
    "        \n",
    "        # Get names of selected features\n",
    "        selected_features_adhd = [all_feature_names[i] for i in np.where(selector_adhd.support_)[0]]\n",
    "        selected_features_sex = [all_feature_names[i] for i in np.where(selector_sex.support_)[0]]\n",
    "        \n",
    "        # Count behavioral interactions in selected features\n",
    "        adhd_interaction_count = sum(1 for f in selected_features_adhd if '*' in f)\n",
    "        sex_interaction_count = sum(1 for f in selected_features_sex if '*' in f)\n",
    "        \n",
    "        print(f\"Selected {len(selected_features_adhd)} features for ADHD_Outcome ({adhd_interaction_count} interactions)\")\n",
    "        print(f\"Selected {len(selected_features_sex)} features for Sex_F ({sex_interaction_count} interactions)\")\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Identify Subgroups for both targets separately\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nIdentifying subgroups for ADHD prediction...\")\n",
    "        train_subgroups_adhd, kmeans_adhd = identify_subgroups(X_train_adhd_selected, n_clusters=n_subgroups)\n",
    "        test_subgroups_adhd = kmeans_adhd.predict(X_test_adhd_selected)\n",
    "        \n",
    "        print(\"\\nIdentifying subgroups for Sex_F prediction...\")\n",
    "        train_subgroups_sex, kmeans_sex = identify_subgroups(X_train_sex_selected, n_clusters=n_subgroups)\n",
    "        test_subgroups_sex = kmeans_sex.predict(X_test_sex_selected)\n",
    "        \n",
    "        # Split training data for validation while preserving subgroup information\n",
    "        X_train_adhd_split, X_val_adhd, y_train_adhd_split, y_val_adhd, subgroups_train_adhd, subgroups_val_adhd = train_test_split(\n",
    "            X_train_adhd_selected, y_train[:, 0], train_subgroups_adhd, \n",
    "            test_size=0.2, random_state=42, stratify=y_train[:, 0]\n",
    "        )\n",
    "        \n",
    "        X_train_sex_split, X_val_sex, y_train_sex_split, y_val_sex, subgroups_train_sex, subgroups_val_sex = train_test_split(\n",
    "            X_train_sex_selected, y_train[:, 1], train_subgroups_sex,\n",
    "            test_size=0.2, random_state=42, stratify=y_train[:, 1]\n",
    "        )\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Train Models by Subgroup for both ADHD and Sex_F\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nTraining ADHD models for each subgroup...\")\n",
    "        \n",
    "        # Initialize dictionaries to store models and thresholds for each subgroup\n",
    "        adhd_models = {}\n",
    "        adhd_thresholds = {}\n",
    "        adhd_metrics = {}\n",
    "        \n",
    "        # Initialize dictionaries for Sex_F\n",
    "        sex_models = {}\n",
    "        sex_thresholds = {}\n",
    "        sex_metrics = {}\n",
    "        \n",
    "        # Process each subgroup for ADHD models\n",
    "        for subgroup in range(n_subgroups):\n",
    "            print(f\"\\nProcessing ADHD subgroup {subgroup+1}...\")\n",
    "            \n",
    "            # Get training data for this subgroup\n",
    "            subgroup_mask = subgroups_train_adhd == subgroup\n",
    "            X_subgroup = X_train_adhd_split[subgroup_mask]\n",
    "            y_subgroup = y_train_adhd_split[subgroup_mask]\n",
    "            \n",
    "            # Get validation data for this subgroup\n",
    "            val_subgroup_mask = subgroups_val_adhd == subgroup\n",
    "            X_val_subgroup = X_val_adhd[val_subgroup_mask]\n",
    "            y_val_subgroup = y_val_adhd[val_subgroup_mask]\n",
    "            \n",
    "            print(f\"  Training samples: {sum(subgroup_mask)}, Validation samples: {sum(val_subgroup_mask)}\")\n",
    "            \n",
    "            # Check if enough samples in subgroup\n",
    "            if sum(subgroup_mask) < 20 or sum(val_subgroup_mask) < 10:\n",
    "                print(f\"  Warning: Subgroup {subgroup+1} has too few samples. Using global model.\")\n",
    "                # Use global data for this subgroup\n",
    "                X_subgroup = X_train_adhd_split\n",
    "                y_subgroup = y_train_adhd_split\n",
    "                X_val_subgroup = X_val_adhd\n",
    "                y_val_subgroup = y_val_adhd\n",
    "            \n",
    "            # Apply SMOTE-ENN for balanced sampling\n",
    "            smote_enn_adhd = SMOTEENN(random_state=42, sampling_strategy='auto', n_jobs=-1)\n",
    "            \n",
    "            # Check if there are enough samples for SMOTE-ENN\n",
    "            if len(np.unique(y_subgroup)) > 1 and min(np.bincount(y_subgroup)) >= 5:\n",
    "                X_subgroup_resampled, y_subgroup_resampled = smote_enn_adhd.fit_resample(X_subgroup, y_subgroup)\n",
    "                print(f\"  Original class distribution: {np.bincount(y_subgroup)}\")\n",
    "                print(f\"  Resampled class distribution: {np.bincount(y_subgroup_resampled)}\")\n",
    "            else:\n",
    "                print(f\"  Warning: Not enough samples for SMOTE-ENN in subgroup {subgroup+1}. Using original data.\")\n",
    "                X_subgroup_resampled, y_subgroup_resampled = X_subgroup, y_subgroup\n",
    "            \n",
    "            # Train ADHD model with XGBoost for this subgroup\n",
    "            xgb_adhd = xgb.XGBClassifier(\n",
    "                objective='binary:logistic',\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='logloss',\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                min_child_weight=2,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                n_estimators=200,\n",
    "                random_state=42\n",
    "            )\n",
    "            xgb_adhd.fit(X_subgroup_resampled, y_subgroup_resampled)\n",
    "            \n",
    "            # Store model\n",
    "            adhd_models[subgroup] = xgb_adhd\n",
    "            \n",
    "            # Get predicted probabilities for this subgroup\n",
    "            adhd_probs = xgb_adhd.predict_proba(X_val_subgroup)[:, 1]\n",
    "            \n",
    "            # Check if validation set has both classes\n",
    "            if len(np.unique(y_val_subgroup)) < 2:\n",
    "                print(f\"  Warning: Validation set for subgroup {subgroup+1} has only one class. Using default threshold.\")\n",
    "                adhd_sens_threshold = 0.5\n",
    "                adhd_sens_metrics = {'sensitivity': 0.9, 'specificity': 0.5, 'accuracy': 0.7}\n",
    "            else:\n",
    "                # Find optimal threshold for high sensitivity\n",
    "                adhd_sens_threshold, _, adhd_sens_metrics = find_optimal_threshold_for_metric(\n",
    "                    y_val_subgroup, adhd_probs, 'sensitivity', 0.90\n",
    "                )\n",
    "            \n",
    "            # Store threshold and metrics\n",
    "            adhd_thresholds[subgroup] = adhd_sens_threshold\n",
    "            adhd_metrics[subgroup] = adhd_sens_metrics\n",
    "            \n",
    "            print(f\"  Optimized threshold: {adhd_sens_threshold:.4f}\")\n",
    "            print(f\"  Sensitivity: {adhd_sens_metrics['sensitivity']:.4f}, \"\n",
    "                  f\"Specificity: {adhd_sens_metrics['specificity']:.4f}, \"\n",
    "                  f\"Accuracy: {adhd_sens_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        # Process each subgroup for Sex_F models\n",
    "        print(\"\\nTraining Sex_F models for each subgroup...\")\n",
    "        for subgroup in range(n_subgroups):\n",
    "            print(f\"\\nProcessing Sex_F subgroup {subgroup+1}...\")\n",
    "            \n",
    "            # Get training data for this subgroup\n",
    "            subgroup_mask = subgroups_train_sex == subgroup\n",
    "            X_subgroup = X_train_sex_split[subgroup_mask]\n",
    "            y_subgroup = y_train_sex_split[subgroup_mask]\n",
    "            \n",
    "            # Get validation data for this subgroup\n",
    "            val_subgroup_mask = subgroups_val_sex == subgroup\n",
    "            X_val_subgroup = X_val_sex[val_subgroup_mask]\n",
    "            y_val_subgroup = y_val_sex[val_subgroup_mask]\n",
    "            \n",
    "            print(f\"  Training samples: {sum(subgroup_mask)}, Validation samples: {sum(val_subgroup_mask)}\")\n",
    "            \n",
    "            # Check if enough samples in subgroup\n",
    "            if sum(subgroup_mask) < 20 or sum(val_subgroup_mask) < 10:\n",
    "                print(f\"  Warning: Subgroup {subgroup+1} has too few samples. Using global model.\")\n",
    "                # Use global data for this subgroup\n",
    "                X_subgroup = X_train_sex_split\n",
    "                y_subgroup = y_train_sex_split\n",
    "                X_val_subgroup = X_val_sex\n",
    "                y_val_subgroup = y_val_sex\n",
    "            \n",
    "            # Apply SMOTE-ENN for balanced sampling\n",
    "            smote_enn_sex = SMOTEENN(random_state=42, sampling_strategy='auto', n_jobs=-1)\n",
    "            \n",
    "            # Check if there are enough samples for SMOTE-ENN\n",
    "            if len(np.unique(y_subgroup)) > 1 and min(np.bincount(y_subgroup)) >= 5:\n",
    "                X_subgroup_resampled, y_subgroup_resampled = smote_enn_sex.fit_resample(X_subgroup, y_subgroup)\n",
    "                print(f\"  Original class distribution: {np.bincount(y_subgroup)}\")\n",
    "                print(f\"  Resampled class distribution: {np.bincount(y_subgroup_resampled)}\")\n",
    "            else:\n",
    "                print(f\"  Warning: Not enough samples for SMOTE-ENN in subgroup {subgroup+1}. Using original data.\")\n",
    "                X_subgroup_resampled, y_subgroup_resampled = X_subgroup, y_subgroup\n",
    "            \n",
    "            # Train Sex_F model with XGBoost for this subgroup\n",
    "            xgb_sex = xgb.XGBClassifier(\n",
    "                objective='binary:logistic',\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='logloss',\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                min_child_weight=2,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                n_estimators=200,\n",
    "                random_state=42\n",
    "            )\n",
    "            xgb_sex.fit(X_subgroup_resampled, y_subgroup_resampled)\n",
    "            \n",
    "            # Store model\n",
    "            sex_models[subgroup] = xgb_sex\n",
    "            \n",
    "            # Get predicted probabilities for this subgroup\n",
    "            sex_probs = xgb_sex.predict_proba(X_val_subgroup)[:, 1]\n",
    "            \n",
    "            # Check if validation set has both classes\n",
    "            if len(np.unique(y_val_subgroup)) < 2:\n",
    "                print(f\"  Warning: Validation set for subgroup {subgroup+1} has only one class. Using default threshold.\")\n",
    "                sex_sens_threshold = 0.5\n",
    "                sex_sens_metrics = {'sensitivity': 0.9, 'specificity': 0.5, 'accuracy': 0.7}\n",
    "            else:\n",
    "                # Find optimal threshold for high sensitivity\n",
    "                sex_sens_threshold, _, sex_sens_metrics = find_optimal_threshold_for_metric(\n",
    "                    y_val_subgroup, sex_probs, 'sensitivity', 0.90\n",
    "                )\n",
    "            \n",
    "            # Store threshold and metrics\n",
    "            sex_thresholds[subgroup] = sex_sens_threshold\n",
    "            sex_metrics[subgroup] = sex_sens_metrics\n",
    "            \n",
    "            print(f\"  Optimized threshold: {sex_sens_threshold:.4f}\")\n",
    "            print(f\"  Sensitivity: {sex_sens_metrics['sensitivity']:.4f}, \"\n",
    "                  f\"Specificity: {sex_sens_metrics['specificity']:.4f}, \"\n",
    "                  f\"Accuracy: {sex_sens_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Retrain on Full Dataset by Subgroup\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nRetraining final models...\")\n",
    "        \n",
    "        # Retrain ADHD models for each subgroup on full data\n",
    "        final_adhd_models = {}\n",
    "        for subgroup in range(n_subgroups):\n",
    "            print(f\"Retraining ADHD model for subgroup {subgroup+1}...\")\n",
    "            \n",
    "            # Get training data for this subgroup\n",
    "            subgroup_mask = train_subgroups_adhd == subgroup\n",
    "            X_subgroup = X_train_adhd_selected[subgroup_mask]\n",
    "            y_subgroup = y_train[:, 0][subgroup_mask]\n",
    "            \n",
    "            # Check if enough samples in subgroup\n",
    "            if sum(subgroup_mask) < 30:\n",
    "                print(f\"  Warning: Subgroup {subgroup+1} has too few samples for final training. Using global model.\")\n",
    "                # Use global data for this subgroup\n",
    "                X_subgroup = X_train_adhd_selected\n",
    "                y_subgroup = y_train[:, 0]\n",
    "            \n",
    "            # Apply SMOTE-ENN for balanced sampling\n",
    "            smote_enn_adhd = SMOTEENN(random_state=42, sampling_strategy='auto', n_jobs=-1)\n",
    "            \n",
    "            # Check if enough samples for SMOTE-ENN\n",
    "            if len(np.unique(y_subgroup)) > 1 and min(np.bincount(y_subgroup)) >= 5:\n",
    "                X_subgroup_resampled, y_subgroup_resampled = smote_enn_adhd.fit_resample(X_subgroup, y_subgroup)\n",
    "            else:\n",
    "                print(f\"  Warning: Not enough samples for SMOTE-ENN in final training. Using original data.\")\n",
    "                X_subgroup_resampled, y_subgroup_resampled = X_subgroup, y_subgroup\n",
    "            \n",
    "            # Train final model\n",
    "            final_xgb_adhd = xgb.XGBClassifier(\n",
    "                objective='binary:logistic',\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='logloss',\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                min_child_weight=2,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                n_estimators=300,\n",
    "                random_state=42\n",
    "            )\n",
    "            final_xgb_adhd.fit(X_subgroup_resampled, y_subgroup_resampled)\n",
    "            \n",
    "            # Store model\n",
    "            final_adhd_models[subgroup] = final_xgb_adhd\n",
    "        \n",
    "        # Retrain Sex_F models for each subgroup on full data\n",
    "        final_sex_models = {}\n",
    "        for subgroup in range(n_subgroups):\n",
    "            print(f\"Retraining Sex_F model for subgroup {subgroup+1}...\")\n",
    "            \n",
    "            # Get training data for this subgroup\n",
    "            subgroup_mask = train_subgroups_sex == subgroup\n",
    "            X_subgroup = X_train_sex_selected[subgroup_mask]\n",
    "            y_subgroup = y_train[:, 1][subgroup_mask]\n",
    "            \n",
    "            # Check if enough samples in subgroup\n",
    "            if sum(subgroup_mask) < 30:\n",
    "                print(f\"  Warning: Subgroup {subgroup+1} has too few samples for final training. Using global model.\")\n",
    "                # Use global data for this subgroup\n",
    "                X_subgroup = X_train_sex_selected\n",
    "                y_subgroup = y_train[:, 1]\n",
    "            \n",
    "            # Apply SMOTE-ENN for balanced sampling\n",
    "            smote_enn_sex = SMOTEENN(random_state=42, sampling_strategy='auto', n_jobs=-1)\n",
    "            \n",
    "            # Check if enough samples for SMOTE-ENN\n",
    "            if len(np.unique(y_subgroup)) > 1 and min(np.bincount(y_subgroup)) >= 5:\n",
    "                X_subgroup_resampled, y_subgroup_resampled = smote_enn_sex.fit_resample(X_subgroup, y_subgroup)\n",
    "            else:\n",
    "                print(f\"  Warning: Not enough samples for SMOTE-ENN in final training. Using original data.\")\n",
    "                X_subgroup_resampled, y_subgroup_resampled = X_subgroup, y_subgroup\n",
    "            \n",
    "            # Train final model\n",
    "            final_xgb_sex = xgb.XGBClassifier(\n",
    "                objective='binary:logistic',\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='logloss',\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                min_child_weight=2,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                n_estimators=300,\n",
    "                random_state=42\n",
    "            )\n",
    "            final_xgb_sex.fit(X_subgroup_resampled, y_subgroup_resampled)\n",
    "            \n",
    "            # Store model\n",
    "            final_sex_models[subgroup] = final_xgb_sex\n",
    "        \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Generate Test Predictions with Subgroup-Specific Thresholds\n",
    "        # -----------------------------------------------------------------------------\n",
    "        print(\"\\nGenerating predictions for test data with subgroup-specific thresholds...\")\n",
    "        \n",
    "        # Initialize arrays for ADHD predictions and probabilities\n",
    "        test_adhd_probs = np.zeros(len(test_df))\n",
    "        test_adhd_preds = np.zeros(len(test_df), dtype=int)\n",
    "        test_adhd_thresholds = np.zeros(len(test_df))\n",
    "        \n",
    "        # Initialize arrays for Sex_F predictions and probabilities\n",
    "        test_sex_probs = np.zeros(len(test_df))\n",
    "        test_sex_preds = np.zeros(len(test_df), dtype=int)\n",
    "        test_sex_thresholds = np.zeros(len(test_df))\n",
    "        \n",
    "        # Store subgroup information\n",
    "        test_adhd_subgroups = test_subgroups_adhd\n",
    "        test_sex_subgroups = test_subgroups_sex\n",
    "        \n",
    "        # Generate predictions for each ADHD subgroup\n",
    "        for subgroup in range(n_subgroups):\n",
    "            # Get test samples belonging to this subgroup\n",
    "            subgroup_mask = test_subgroups_adhd == subgroup\n",
    "            \n",
    "            # Skip if no samples in this subgroup\n",
    "            if not np.any(subgroup_mask):\n",
    "                continue\n",
    "            \n",
    "            # Get model and threshold for this subgroup\n",
    "            model = final_adhd_models[subgroup]\n",
    "            threshold = adhd_thresholds[subgroup]\n",
    "            \n",
    "            # Generate probabilities for this subgroup\n",
    "            subgroup_probs = model.predict_proba(X_test_adhd_selected[subgroup_mask])[:, 1]\n",
    "            \n",
    "            # Store probabilities and thresholds\n",
    "            test_adhd_probs[subgroup_mask] = subgroup_probs\n",
    "            test_adhd_thresholds[subgroup_mask] = threshold\n",
    "            \n",
    "            # Apply subgroup-specific threshold\n",
    "            test_adhd_preds[subgroup_mask] = (subgroup_probs >= threshold).astype(int)\n",
    "            \n",
    "            print(f\"ADHD Subgroup {subgroup+1}: Applied threshold {threshold:.4f} to {np.sum(subgroup_mask)} samples\")\n",
    "        \n",
    "        # Generate predictions for each Sex_F subgroup\n",
    "        for subgroup in range(n_subgroups):\n",
    "            # Get test samples belonging to this subgroup\n",
    "            subgroup_mask = test_subgroups_sex == subgroup\n",
    "            \n",
    "            # Skip if no samples in this subgroup\n",
    "            if not np.any(subgroup_mask):\n",
    "                continue\n",
    "            \n",
    "            # Get model and threshold for this subgroup\n",
    "            model = final_sex_models[subgroup]\n",
    "            threshold = sex_thresholds[subgroup]\n",
    "            \n",
    "            # Generate probabilities for this subgroup\n",
    "            subgroup_probs = model.predict_proba(X_test_sex_selected[subgroup_mask])[:, 1]\n",
    "            \n",
    "            # Store probabilities and thresholds\n",
    "            test_sex_probs[subgroup_mask] = subgroup_probs\n",
    "            test_sex_thresholds[subgroup_mask] = threshold\n",
    "            \n",
    "            # Apply subgroup-specific threshold\n",
    "            test_sex_preds[subgroup_mask] = (subgroup_probs >= threshold).astype(int)\n",
    "            \n",
    "            print(f\"Sex_F Subgroup {subgroup+1}: Applied threshold {threshold:.4f} to {np.sum(subgroup_mask)} samples\")\n",
    "        \n",
    "        # Ensure participant_id is available\n",
    "        if 'participant_id' not in test_df.columns:\n",
    "            print(\"Warning: participant_id column not found in test data. Using row index as ID.\")\n",
    "            participant_ids = np.arange(1, len(test_df) + 1)\n",
    "        else:\n",
    "            participant_ids = test_df['participant_id'].values\n",
    "        \n",
    "        # Create submission DataFrame\n",
    "        submission_df = pd.DataFrame({\n",
    "            'participant_id': participant_ids,\n",
    "            'ADHD_Outcome': test_adhd_preds,\n",
    "            'Sex_F': test_sex_preds\n",
    "        })\n",
    "        \n",
    "        # Create detailed DataFrame with predictions, probabilities, thresholds and subgroups\n",
    "        details_df = pd.DataFrame({\n",
    "            'participant_id': participant_ids,\n",
    "            'ADHD_subgroup': test_adhd_subgroups + 1,  # 1-indexed instead of 0-indexed\n",
    "            'Sex_F_subgroup': test_sex_subgroups + 1,  # 1-indexed instead of 0-indexed\n",
    "            'ADHD_Probability': test_adhd_probs,\n",
    "            'Sex_F_Probability': test_sex_probs,\n",
    "            'ADHD_Threshold': test_adhd_thresholds,\n",
    "            'Sex_F_Threshold': test_sex_thresholds,\n",
    "            'ADHD_Prediction': test_adhd_preds,\n",
    "            'Sex_F_Prediction': test_sex_preds\n",
    "        })\n",
    "        \n",
    "        # Save to CSV files\n",
    "        submission_df.to_csv(output_filename, index=False)\n",
    "        details_df.to_csv(output_filename.replace('.csv', '_details.csv'), index=False)\n",
    "        \n",
    "        # Save ADHD subgroup information and thresholds\n",
    "        adhd_subgroup_info = pd.DataFrame({\n",
    "            'subgroup': np.arange(n_subgroups) + 1,\n",
    "            'threshold': [adhd_thresholds[sg] for sg in range(n_subgroups)],\n",
    "            'sensitivity': [adhd_metrics[sg]['sensitivity'] for sg in range(n_subgroups)],\n",
    "            'specificity': [adhd_metrics[sg]['specificity'] for sg in range(n_subgroups)],\n",
    "            'accuracy': [adhd_metrics[sg]['accuracy'] for sg in range(n_subgroups)]\n",
    "        })\n",
    "        adhd_subgroup_info.to_csv(output_filename.replace('.csv', '_adhd_subgroups.csv'), index=False)\n",
    "        \n",
    "        # Save Sex_F subgroup information and thresholds\n",
    "        sex_subgroup_info = pd.DataFrame({\n",
    "            'subgroup': np.arange(n_subgroups) + 1,\n",
    "            'threshold': [sex_thresholds[sg] for sg in range(n_subgroups)],\n",
    "            'sensitivity': [sex_metrics[sg]['sensitivity'] for sg in range(n_subgroups)],\n",
    "            'specificity': [sex_metrics[sg]['specificity'] for sg in range(n_subgroups)],\n",
    "            'accuracy': [sex_metrics[sg]['accuracy'] for sg in range(n_subgroups)]\n",
    "        })\n",
    "        sex_subgroup_info.to_csv(output_filename.replace('.csv', '_sex_subgroups.csv'), index=False)\n",
    "        \n",
    "        print(f\"\\nPredictions with subgroup-specific thresholds saved to: {output_filename}\")\n",
    "        print(f\"Detailed prediction data saved to: {output_filename.replace('.csv', '_details.csv')}\")\n",
    "        print(f\"ADHD subgroup information saved to: {output_filename.replace('.csv', '_adhd_subgroups.csv')}\")\n",
    "        print(f\"Sex_F subgroup information saved to: {output_filename.replace('.csv', '_sex_subgroups.csv')}\")\n",
    "        \n",
    "        # Print formatted outputs\n",
    "        print(\"\\nFormatted predictions with subgroup-specific thresholds:\")\n",
    "        print(\"participant_id,ADHD_Outcome,Sex_F\")\n",
    "        for _, row in submission_df.iterrows():\n",
    "            print(f\"{row['participant_id']}, {row['ADHD_Outcome']}, {row['Sex_F']}\")\n",
    "        \n",
    "        # Print summary of subgroup thresholds for ADHD\n",
    "        print(\"\\nSubgroup-specific thresholds for ADHD prediction:\")\n",
    "        for subgroup in range(n_subgroups):\n",
    "            print(f\"Subgroup {subgroup+1}: Threshold = {adhd_thresholds[subgroup]:.4f}, \"\n",
    "                  f\"Sensitivity = {adhd_metrics[subgroup]['sensitivity']:.4f}, \"\n",
    "                  f\"Specificity = {adhd_metrics[subgroup]['specificity']:.4f}\")\n",
    "        \n",
    "        # Print summary of subgroup thresholds for Sex_F\n",
    "        print(\"\\nSubgroup-specific thresholds for Sex_F prediction:\")\n",
    "        for subgroup in range(n_subgroups):\n",
    "            print(f\"Subgroup {subgroup+1}: Threshold = {sex_thresholds[subgroup]:.4f}, \"\n",
    "                  f\"Sensitivity = {sex_metrics[subgroup]['sensitivity']:.4f}, \"\n",
    "                  f\"Specificity = {sex_metrics[subgroup]['specificity']:.4f}\")\n",
    "                  \n",
    "        # -----------------------------------------------------------------------------\n",
    "        # Return Results\n",
    "        # -----------------------------------------------------------------------------\n",
    "        return {\n",
    "            'adhd_subgroups': {\n",
    "                'count': n_subgroups,\n",
    "                'train_distribution': np.bincount(train_subgroups_adhd),\n",
    "                'test_distribution': np.bincount(test_subgroups_adhd),\n",
    "                'thresholds': {subgroup: adhd_thresholds[subgroup] for subgroup in range(n_subgroups)},\n",
    "                'metrics': {subgroup: adhd_metrics[subgroup] for subgroup in range(n_subgroups)}\n",
    "            },\n",
    "            'sex_subgroups': {\n",
    "                'count': n_subgroups,\n",
    "                'train_distribution': np.bincount(train_subgroups_sex),\n",
    "                'test_distribution': np.bincount(test_subgroups_sex),\n",
    "                'thresholds': {subgroup: sex_thresholds[subgroup] for subgroup in range(n_subgroups)},\n",
    "                'metrics': {subgroup: sex_metrics[subgroup] for subgroup in range(n_subgroups)}\n",
    "            },\n",
    "            'submission': submission_df,\n",
    "            'details': details_df,\n",
    "            'adhd_subgroup_info': adhd_subgroup_info,\n",
    "            'sex_subgroup_info': sex_subgroup_info\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Execute the function if run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Try to access the existing test_df variable if available\n",
    "    if 'test_df' in globals():\n",
    "        results = multi_outcome_predictions_with_subgroups(test_dataset=test_df)\n",
    "    else:\n",
    "        results = multi_outcome_predictions_with_subgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded details file with 304 rows\n",
      "Loaded ADHD subgroups file with 3 subgroups\n",
      "Loaded Sex_F subgroups file with 3 subgroups\n",
      "\n",
      "Best ADHD subgroup: 2.0 with sensitivity 0.9032\n",
      "Best Sex_F subgroup: 1.0 with sensitivity 0.9167\n",
      "ADHD threshold from best subgroup: 0.0200\n",
      "Sex_F threshold from best subgroup: 0.1500\n",
      "\n",
      "Changes from original subgroup-specific predictions:\n",
      "ADHD predictions changed: 3 (1.0%)\n",
      "Sex_F predictions changed: 20 (6.6%)\n",
      "\n",
      "Class distribution in high sensitivity predictions:\n",
      "ADHD positive: 291 (95.7%)\n",
      "Sex_F positive: 280 (92.1%)\n",
      "\n",
      "High sensitivity submission saved to: high_sensitivity_submission.csv\n",
      "\n",
      "Formatted predictions (High Sensitivity):\n",
      "participant_id,ADHD_Outcome,Sex_F\n",
      "Cfwaf5FX7jWK, 1, 1\n",
      "vhGrzmvA3Hjq, 1, 1\n",
      "ULliyEXjy4OV, 1, 1\n",
      "LZfeAb1xMtql, 1, 1\n",
      "EnFOUv0YK1RG, 1, 1\n",
      "3VbkvJ22j9Fu, 1, 1\n",
      "PRKZcnOgqcuk, 1, 1\n",
      "DuVUuyMZi5qV, 1, 1\n",
      "uM4etVLZrgMg, 1, 1\n",
      "BpzyExrET5ta, 1, 1\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_high_sensitivity_submission(details_file, adhd_subgroups_file, sex_subgroups_file, output_file='high_sensitivity_submission.csv'):\n",
    "    \"\"\"\n",
    "    Creates a submission file that uses the subgroup with the highest sensitivity for each target.\n",
    "    \n",
    "    Parameters:\n",
    "        details_file: Path to the detailed predictions file with all subgroups\n",
    "        adhd_subgroups_file: Path to the ADHD subgroups metrics file\n",
    "        sex_subgroups_file: Path to the Sex_F subgroups metrics file\n",
    "        output_file: Path to save the output submission file\n",
    "    \n",
    "    Returns:\n",
    "        The submission dataframe with highest sensitivity predictions\n",
    "    \"\"\"\n",
    "    # Load the detailed predictions file\n",
    "    try:\n",
    "        details_df = pd.read_csv(details_file)\n",
    "        print(f\"Loaded details file with {len(details_df)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading details file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Load the subgroup metrics files\n",
    "    try:\n",
    "        adhd_subgroups = pd.read_csv(adhd_subgroups_file)\n",
    "        sex_subgroups = pd.read_csv(sex_subgroups_file)\n",
    "        \n",
    "        print(f\"Loaded ADHD subgroups file with {len(adhd_subgroups)} subgroups\")\n",
    "        print(f\"Loaded Sex_F subgroups file with {len(sex_subgroups)} subgroups\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading subgroups files: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Find the subgroup with highest sensitivity for each target\n",
    "    adhd_best_subgroup = adhd_subgroups.loc[adhd_subgroups['sensitivity'].idxmax()]\n",
    "    sex_best_subgroup = sex_subgroups.loc[sex_subgroups['sensitivity'].idxmax()]\n",
    "    \n",
    "    print(f\"\\nBest ADHD subgroup: {adhd_best_subgroup['subgroup']} with sensitivity {adhd_best_subgroup['sensitivity']:.4f}\")\n",
    "    print(f\"Best Sex_F subgroup: {sex_best_subgroup['subgroup']} with sensitivity {sex_best_subgroup['sensitivity']:.4f}\")\n",
    "    \n",
    "    # Get the thresholds for these best subgroups\n",
    "    adhd_best_threshold = adhd_best_subgroup['threshold']\n",
    "    sex_best_threshold = sex_best_subgroup['threshold']\n",
    "    \n",
    "    print(f\"ADHD threshold from best subgroup: {adhd_best_threshold:.4f}\")\n",
    "    print(f\"Sex_F threshold from best subgroup: {sex_best_threshold:.4f}\")\n",
    "    \n",
    "    # Apply these thresholds to all predictions, regardless of original subgroup\n",
    "    details_df['ADHD_HighSens_Prediction'] = (details_df['ADHD_Probability'] >= adhd_best_threshold).astype(int)\n",
    "    details_df['Sex_F_HighSens_Prediction'] = (details_df['Sex_F_Probability'] >= sex_best_threshold).astype(int)\n",
    "    \n",
    "    # Create a new submission dataframe with the high sensitivity predictions\n",
    "    submission_df = pd.DataFrame({\n",
    "        'participant_id': details_df['participant_id'],\n",
    "        'ADHD_Outcome': details_df['ADHD_HighSens_Prediction'],\n",
    "        'Sex_F': details_df['Sex_F_HighSens_Prediction']\n",
    "    })\n",
    "    \n",
    "    # Compare with original predictions\n",
    "    adhd_changes = (submission_df['ADHD_Outcome'] != details_df['ADHD_Prediction']).sum()\n",
    "    sex_changes = (submission_df['Sex_F'] != details_df['Sex_F_Prediction']).sum()\n",
    "    \n",
    "    print(f\"\\nChanges from original subgroup-specific predictions:\")\n",
    "    print(f\"ADHD predictions changed: {adhd_changes} ({adhd_changes/len(details_df)*100:.1f}%)\")\n",
    "    print(f\"Sex_F predictions changed: {sex_changes} ({sex_changes/len(details_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Calculate class distribution in final predictions\n",
    "    adhd_positive = submission_df['ADHD_Outcome'].sum()\n",
    "    sex_positive = submission_df['Sex_F'].sum()\n",
    "    \n",
    "    print(f\"\\nClass distribution in high sensitivity predictions:\")\n",
    "    print(f\"ADHD positive: {adhd_positive} ({adhd_positive/len(submission_df)*100:.1f}%)\")\n",
    "    print(f\"Sex_F positive: {sex_positive} ({sex_positive/len(submission_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Save the submission file\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nHigh sensitivity submission saved to: {output_file}\")\n",
    "    \n",
    "    # Print formatted outputs\n",
    "    print(\"\\nFormatted predictions (High Sensitivity):\")\n",
    "    print(\"participant_id,ADHD_Outcome,Sex_F\")\n",
    "    for _, row in submission_df.head(10).iterrows():\n",
    "        print(f\"{row['participant_id']}, {row['ADHD_Outcome']}, {row['Sex_F']}\")\n",
    "    print(\"...\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Default file paths - adjust these to match your file locations\n",
    "    details_file = 'multi_outcome_subgroups_details.csv'\n",
    "    adhd_subgroups_file = 'multi_outcome_subgroups_adhd_subgroups.csv'\n",
    "    sex_subgroups_file = 'multi_outcome_subgroups_sex_subgroups.csv'\n",
    "    \n",
    "    # Create high sensitivity submission\n",
    "    high_sens_submission = create_high_sensitivity_submission(\n",
    "        details_file,\n",
    "        adhd_subgroups_file,\n",
    "        sex_subgroups_file,\n",
    "        'high_sensitivity_submission.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (3.0.0)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdur\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "Creating Specialized Models for Each Target and Subgroup\n",
      "**************************************************\n",
      "Loaded details file with 304 rows\n",
      "Columns in details file: ['participant_id', 'ADHD_subgroup', 'Sex_F_subgroup', 'ADHD_Probability', 'Sex_F_Probability', 'ADHD_Threshold', 'Sex_F_Threshold', 'ADHD_Prediction', 'Sex_F_Prediction']\n",
      "Loaded ADHD subgroups file with 3 subgroups\n",
      "Loaded Sex_F subgroups file with 3 subgroups\n",
      "Warning: No subgroup column found. Using default 'all' subgroup.\n",
      "Error: Not enough feature columns identified. Please check your data.\n",
      "Current columns: ['participant_id', 'ADHD_subgroup', 'Sex_F_subgroup', 'ADHD_Probability', 'Sex_F_Probability', 'ADHD_Threshold', 'Sex_F_Threshold', 'ADHD_Prediction', 'Sex_F_Prediction', 'subgroup']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_specialized_models_submission(\n",
    "    details_file, \n",
    "    adhd_subgroups_file, \n",
    "    sex_subgroups_file, \n",
    "    output_dir='specialized_models_results',\n",
    "    output_file='specialized_models_submission.csv'\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates specialized models for each target and subgroup, then makes a submission file.\n",
    "    \n",
    "    Parameters:\n",
    "        details_file: Path to the detailed predictions file with all subgroups\n",
    "        adhd_subgroups_file: Path to the ADHD subgroups metrics file\n",
    "        sex_subgroups_file: Path to the Sex_F subgroups metrics file\n",
    "        output_dir: Directory to save model outputs\n",
    "        output_file: Path to save the final submission file\n",
    "    \n",
    "    Returns:\n",
    "        The submission dataframe with predictions from the best models\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'*'*50}\")\n",
    "    print(f\"Creating Specialized Models for Each Target and Subgroup\")\n",
    "    print(f\"{'*'*50}\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Load the detailed predictions file\n",
    "    try:\n",
    "        details_df = pd.read_csv(details_file)\n",
    "        print(f\"Loaded details file with {len(details_df)} rows\")\n",
    "        print(f\"Columns in details file: {details_df.columns.tolist()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading details file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Load the subgroup metrics files\n",
    "    try:\n",
    "        adhd_subgroups = pd.read_csv(adhd_subgroups_file)\n",
    "        sex_subgroups = pd.read_csv(sex_subgroups_file)\n",
    "        \n",
    "        print(f\"Loaded ADHD subgroups file with {len(adhd_subgroups)} subgroups\")\n",
    "        print(f\"Loaded Sex_F subgroups file with {len(sex_subgroups)} subgroups\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading subgroups files: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # If subgroup column doesn't exist, create it\n",
    "    if 'subgroup' not in details_df.columns:\n",
    "        # Extract subgroup information from the files\n",
    "        unique_subgroups = set(adhd_subgroups['subgroup'].unique()) | set(sex_subgroups['subgroup'].unique())\n",
    "        \n",
    "        # This approach assumes you have subgroup info in the filenames or another way to identify\n",
    "        # For now, we'll use a default subgroup if we can't determine it\n",
    "        details_df['subgroup'] = 'all'\n",
    "        print(\"Warning: No subgroup column found. Using default 'all' subgroup.\")\n",
    "    \n",
    "    # Filter out non-feature columns (by keyword detection)\n",
    "    non_feature_keywords = ['participant_id', 'subgroup', 'prediction', 'probability', 'outcome', 'ADHD', 'Sex']\n",
    "    feature_cols = [col for col in details_df.columns if not any(keyword.lower() in col.lower() for keyword in non_feature_keywords)]\n",
    "    \n",
    "    # Make sure we have some feature columns\n",
    "    if len(feature_cols) < 2:\n",
    "        print(\"Error: Not enough feature columns identified. Please check your data.\")\n",
    "        print(f\"Current columns: {details_df.columns.tolist()}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Using {len(feature_cols)} feature columns\")\n",
    "    \n",
    "    # Define targets and their corresponding columns\n",
    "    # Autodetect target columns and probability columns\n",
    "    if 'ADHD_Outcome' in details_df.columns:\n",
    "        adhd_target = 'ADHD_Outcome'\n",
    "    elif 'ADHD_Prediction' in details_df.columns:\n",
    "        adhd_target = 'ADHD_Prediction'\n",
    "    else:\n",
    "        # Look for any column with ADHD in the name\n",
    "        adhd_cols = [col for col in details_df.columns if 'ADHD' in col and 'Probability' not in col]\n",
    "        if adhd_cols:\n",
    "            adhd_target = adhd_cols[0]\n",
    "        else:\n",
    "            print(\"Error: Could not find ADHD target column\")\n",
    "            return None\n",
    "    \n",
    "    if 'Sex_F' in details_df.columns:\n",
    "        sex_target = 'Sex_F'\n",
    "    elif 'Sex_F_Prediction' in details_df.columns:\n",
    "        sex_target = 'Sex_F_Prediction'\n",
    "    else:\n",
    "        # Look for any column with Sex in the name\n",
    "        sex_cols = [col for col in details_df.columns if 'Sex' in col and 'Probability' not in col]\n",
    "        if sex_cols:\n",
    "            sex_target = sex_cols[0]\n",
    "        else:\n",
    "            print(\"Error: Could not find Sex_F target column\")\n",
    "            return None\n",
    "    \n",
    "    # Autodetect probability columns\n",
    "    if 'ADHD_Probability' in details_df.columns:\n",
    "        adhd_prob = 'ADHD_Probability'\n",
    "    else:\n",
    "        # Look for any column with ADHD and Probability in the name\n",
    "        adhd_prob_cols = [col for col in details_df.columns if 'ADHD' in col and 'Probability' in col]\n",
    "        if adhd_prob_cols:\n",
    "            adhd_prob = adhd_prob_cols[0]\n",
    "        else:\n",
    "            print(\"Warning: Could not find ADHD probability column. Using 0.5 threshold for predictions.\")\n",
    "            adhd_prob = None\n",
    "    \n",
    "    if 'Sex_F_Probability' in details_df.columns:\n",
    "        sex_prob = 'Sex_F_Probability'\n",
    "    else:\n",
    "        # Look for any column with Sex and Probability in the name\n",
    "        sex_prob_cols = [col for col in details_df.columns if 'Sex' in col and 'Probability' in col]\n",
    "        if sex_prob_cols:\n",
    "            sex_prob = sex_prob_cols[0]\n",
    "        else:\n",
    "            print(\"Warning: Could not find Sex_F probability column. Using 0.5 threshold for predictions.\")\n",
    "            sex_prob = None\n",
    "    \n",
    "    targets = {\n",
    "        'ADHD_Outcome': adhd_target,\n",
    "        'Sex_F': sex_target\n",
    "    }\n",
    "    \n",
    "    print(f\"Target columns: ADHD_Outcome = '{adhd_target}', Sex_F = '{sex_target}'\")\n",
    "    if adhd_prob:\n",
    "        print(f\"ADHD probability column: '{adhd_prob}'\")\n",
    "    if sex_prob:\n",
    "        print(f\"Sex_F probability column: '{sex_prob}'\")\n",
    "    \n",
    "    # Get unique subgroups\n",
    "    unique_subgroups = details_df['subgroup'].unique()\n",
    "    print(f\"Found {len(unique_subgroups)} unique subgroups: {unique_subgroups}\")\n",
    "    \n",
    "    # Define the models to try for each target-subgroup\n",
    "    models = {\n",
    "        'logistic': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "        'rf': RandomForestClassifier(class_weight='balanced', n_jobs=-1),\n",
    "        'xgb': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    }\n",
    "    \n",
    "    # Define parameter grids for each model type\n",
    "    param_grids = {\n",
    "        'logistic': {\n",
    "            'C': [0.1, 1.0, 10.0]\n",
    "        },\n",
    "        'rf': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [None, 10]\n",
    "        },\n",
    "        'xgb': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Dictionary to store best models and results\n",
    "    best_models = {}\n",
    "    results = {'ADHD_Outcome': pd.DataFrame(), 'Sex_F': pd.DataFrame()}\n",
    "    \n",
    "    # Train specialized models for each target and subgroup\n",
    "    for target_name, target_col in targets.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training models for target: {target_name} (column: {target_col})\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # For each subgroup\n",
    "        for subgroup in unique_subgroups:\n",
    "            print(f\"\\n{'-'*30}\")\n",
    "            print(f\"Training models for subgroup: {subgroup}\")\n",
    "            \n",
    "            # Get subgroup data\n",
    "            subgroup_df = details_df[details_df['subgroup'] == subgroup].copy()\n",
    "            \n",
    "            # Skip if not enough data\n",
    "            if len(subgroup_df) < 30:\n",
    "                print(f\"Skipping subgroup {subgroup} due to insufficient samples ({len(subgroup_df)} rows)\")\n",
    "                continue\n",
    "            \n",
    "            # Prepare features\n",
    "            X = subgroup_df[feature_cols]\n",
    "            y = subgroup_df[target_col]\n",
    "            \n",
    "            # Skip if all values are the same\n",
    "            if y.nunique() < 2:\n",
    "                print(f\"Skipping subgroup {subgroup} because all target values are the same\")\n",
    "                continue\n",
    "            \n",
    "            # Check for sufficient positive cases\n",
    "            if y.sum() < 5 or (len(y) - y.sum()) < 5:\n",
    "                print(f\"Skipping subgroup {subgroup} due to class imbalance (only {y.sum()} positive samples)\")\n",
    "                continue\n",
    "            \n",
    "            # Train-test split\n",
    "            try:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=0.3, random_state=42, stratify=y\n",
    "                )\n",
    "                \n",
    "                # Feature scaling\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_test_scaled = scaler.transform(X_test)\n",
    "                \n",
    "                # Track best model for this subgroup\n",
    "                best_sensitivity = -1\n",
    "                best_model_info = None\n",
    "                \n",
    "                # Try different model types\n",
    "                for model_name, model in models.items():\n",
    "                    print(f\"Training {model_name} for {target_name}-{subgroup}\")\n",
    "                    \n",
    "                    try:\n",
    "                        # Parameter tuning with cross-validation\n",
    "                        grid_search = GridSearchCV(\n",
    "                            model, \n",
    "                            param_grids[model_name],\n",
    "                            cv=5,\n",
    "                            scoring='recall',  # Optimize for sensitivity/recall\n",
    "                            n_jobs=-1\n",
    "                        )\n",
    "                        \n",
    "                        # Train the model\n",
    "                        grid_search.fit(X_train_scaled, y_train)\n",
    "                        best_model = grid_search.best_estimator_\n",
    "                        \n",
    "                        # Make predictions\n",
    "                        y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "                        \n",
    "                        # Find optimal threshold for sensitivity\n",
    "                        thresholds = np.linspace(0.1, 0.9, 9)\n",
    "                        best_threshold = 0.5\n",
    "                        best_threshold_sensitivity = -1\n",
    "                        \n",
    "                        for threshold in thresholds:\n",
    "                            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "                            sensitivity = recall_score(y_test, y_pred, zero_division=0)\n",
    "                            \n",
    "                            if sensitivity > best_threshold_sensitivity:\n",
    "                                best_threshold_sensitivity = sensitivity\n",
    "                                best_threshold = threshold\n",
    "                        \n",
    "                        # Final evaluation with best threshold\n",
    "                        y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
    "                        accuracy = accuracy_score(y_test, y_pred)\n",
    "                        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "                        recall = recall_score(y_test, y_pred, zero_division=0)  # sensitivity\n",
    "                        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "                        auc = roc_auc_score(y_test, y_pred_proba) if len(np.unique(y_test)) > 1 else 0\n",
    "                        \n",
    "                        print(f\"{model_name} sensitivity: {recall:.4f}, threshold: {best_threshold:.2f}\")\n",
    "                        \n",
    "                        # Add to results DataFrame\n",
    "                        results[target_name] = pd.concat([\n",
    "                            results[target_name],\n",
    "                            pd.DataFrame([{\n",
    "                                'target': target_name,\n",
    "                                'subgroup': subgroup,\n",
    "                                'model_type': model_name,\n",
    "                                'threshold': best_threshold,\n",
    "                                'sensitivity': recall,\n",
    "                                'accuracy': accuracy,\n",
    "                                'precision': precision,\n",
    "                                'f1': f1,\n",
    "                                'auc': auc\n",
    "                            }])\n",
    "                        ])\n",
    "                        \n",
    "                        # Update best model if better\n",
    "                        if recall > best_sensitivity:\n",
    "                            best_sensitivity = recall\n",
    "                            best_model_info = {\n",
    "                                'model': best_model,\n",
    "                                'model_type': model_name,\n",
    "                                'threshold': best_threshold,\n",
    "                                'sensitivity': recall,\n",
    "                                'scaler': scaler,\n",
    "                                'feature_cols': feature_cols  # Store feature columns used\n",
    "                            }\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error training {model_name} for {target_name}-{subgroup}: {e}\")\n",
    "                \n",
    "                # Store best model for this target-subgroup\n",
    "                if best_model_info is not None:\n",
    "                    model_key = f\"{target_name}_{subgroup}\"\n",
    "                    best_models[model_key] = best_model_info\n",
    "                    \n",
    "                    # Save model to disk\n",
    "                    model_file = os.path.join(output_dir, f\"{model_key}.pkl\")\n",
    "                    with open(model_file, 'wb') as f:\n",
    "                        pickle.dump(best_model_info, f)\n",
    "                    \n",
    "                    print(f\"Best model for {target_name}-{subgroup}: {best_model_info['model_type']} with sensitivity {best_model_info['sensitivity']:.4f}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error training models for {target_name}-{subgroup}: {e}\")\n",
    "    \n",
    "    # Save results to CSV\n",
    "    for target_name, result_df in results.items():\n",
    "        if not result_df.empty:\n",
    "            results_file = os.path.join(output_dir, f\"{target_name}_subgroup_models.csv\")\n",
    "            result_df.to_csv(results_file, index=False)\n",
    "            print(f\"\\nResults for {target_name} saved to {results_file}\")\n",
    "    \n",
    "    # Find the best overall model for each target\n",
    "    best_overall = {}\n",
    "    for target_name in targets.keys():\n",
    "        if not results[target_name].empty:\n",
    "            best_idx = results[target_name]['sensitivity'].idxmax()\n",
    "            best_subgroup_model = results[target_name].loc[best_idx]\n",
    "            \n",
    "            best_overall[target_name] = {\n",
    "                'subgroup': best_subgroup_model['subgroup'],\n",
    "                'model_type': best_subgroup_model['model_type'],\n",
    "                'threshold': best_subgroup_model['threshold'],\n",
    "                'sensitivity': best_subgroup_model['sensitivity']\n",
    "            }\n",
    "            \n",
    "            print(f\"\\nBest model for {target_name}:\")\n",
    "            print(f\"Subgroup: {best_overall[target_name]['subgroup']}\")\n",
    "            print(f\"Model type: {best_overall[target_name]['model_type']}\")\n",
    "            print(f\"Threshold: {best_overall[target_name]['threshold']:.4f}\")\n",
    "            print(f\"Sensitivity: {best_overall[target_name]['sensitivity']:.4f}\")\n",
    "    \n",
    "    # Create a copy of details_df for new predictions\n",
    "    predictions_df = details_df.copy()\n",
    "    \n",
    "    # Add prediction columns\n",
    "    predictions_df['ADHD_Specialized_Prediction'] = 0\n",
    "    predictions_df['Sex_F_Specialized_Prediction'] = 0\n",
    "    \n",
    "    # Generate predictions for each sample based on its subgroup\n",
    "    print(\"\\nGenerating predictions using specialized models...\")\n",
    "    \n",
    "    # Apply the trained models to make predictions\n",
    "    for idx, row in predictions_df.iterrows():\n",
    "        subgroup = row['subgroup']\n",
    "        \n",
    "        for target_name in targets.keys():\n",
    "            model_key = f\"{target_name}_{subgroup}\"\n",
    "            \n",
    "            # Check if we have a model for this target-subgroup\n",
    "            if model_key in best_models:\n",
    "                model_info = best_models[model_key]\n",
    "                model = model_info['model']\n",
    "                threshold = model_info['threshold']\n",
    "                scaler = model_info['scaler']\n",
    "                feature_cols = model_info['feature_cols']\n",
    "                \n",
    "                # Make prediction\n",
    "                features = row[feature_cols].values.reshape(1, -1)\n",
    "                features_scaled = scaler.transform(features)\n",
    "                probability = model.predict_proba(features_scaled)[0, 1]\n",
    "                prediction = 1 if probability >= threshold else 0\n",
    "                \n",
    "                # Store prediction\n",
    "                pred_col = f\"{target_name}_Specialized_Prediction\"\n",
    "                predictions_df.at[idx, pred_col] = prediction\n",
    "            else:\n",
    "                # Use the best overall model for this target as fallback\n",
    "                if target_name in best_overall:\n",
    "                    best_subgroup = best_overall[target_name]['subgroup']\n",
    "                    fallback_key = f\"{target_name}_{best_subgroup}\"\n",
    "                    \n",
    "                    if fallback_key in best_models:\n",
    "                        model_info = best_models[fallback_key]\n",
    "                        model = model_info['model']\n",
    "                        threshold = model_info['threshold']\n",
    "                        scaler = model_info['scaler']\n",
    "                        feature_cols = model_info['feature_cols']\n",
    "                        \n",
    "                        # Make prediction\n",
    "                        features = row[feature_cols].values.reshape(1, -1)\n",
    "                        features_scaled = scaler.transform(features)\n",
    "                        probability = model.predict_proba(features_scaled)[0, 1]\n",
    "                        prediction = 1 if probability >= threshold else 0\n",
    "                        \n",
    "                        # Store prediction\n",
    "                        pred_col = f\"{target_name}_Specialized_Prediction\"\n",
    "                        predictions_df.at[idx, pred_col] = prediction\n",
    "                \n",
    "                # If we have no models at all (unlikely), use the original predictions\n",
    "                else:\n",
    "                    if target_name == 'ADHD_Outcome' and adhd_target in predictions_df.columns:\n",
    "                        predictions_df.at[idx, 'ADHD_Specialized_Prediction'] = predictions_df.at[idx, adhd_target]\n",
    "                    \n",
    "                    if target_name == 'Sex_F' and sex_target in predictions_df.columns:\n",
    "                        predictions_df.at[idx, 'Sex_F_Specialized_Prediction'] = predictions_df.at[idx, sex_target]\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'participant_id': predictions_df['participant_id'],\n",
    "        'ADHD_Outcome': predictions_df['ADHD_Specialized_Prediction'],\n",
    "        'Sex_F': predictions_df['Sex_F_Specialized_Prediction']\n",
    "    })\n",
    "    \n",
    "    # Save detailed predictions file\n",
    "    detailed_file = os.path.join(output_dir, 'specialized_models_detailed.csv')\n",
    "    predictions_df.to_csv(detailed_file, index=False)\n",
    "    print(f\"Saved detailed predictions to {detailed_file}\")\n",
    "    \n",
    "    # Save submission file\n",
    "    submission_path = os.path.join(output_dir, output_file)\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"Saved submission file to {submission_path}\")\n",
    "    \n",
    "    # Calculate class distribution in final predictions\n",
    "    for target, col in zip(['ADHD_Outcome', 'Sex_F'], ['ADHD_Specialized_Prediction', 'Sex_F_Specialized_Prediction']):\n",
    "        positive_count = predictions_df[col].sum()\n",
    "        positive_percent = positive_count / len(predictions_df) * 100\n",
    "        print(f\"{target} positive predictions: {positive_count} ({positive_percent:.1f}%)\")\n",
    "    \n",
    "    # Print formatted outputs\n",
    "    print(\"\\nFormatted predictions (Specialized Models):\")\n",
    "    print(\"participant_id,ADHD_Outcome,Sex_F\")\n",
    "    for _, row in submission_df.head(10).iterrows():\n",
    "        print(f\"{row['participant_id']},{row['ADHD_Outcome']},{row['Sex_F']}\")\n",
    "    print(\"...\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run the specialized models solution with command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Create specialized models for ADHD_Outcome and Sex_F targets')\n",
    "    \n",
    "    parser.add_argument('--details', type=str, default='multi_outcome_subgroups_details.csv',\n",
    "                        help='Path to the detailed predictions file')\n",
    "    parser.add_argument('--adhd_subgroups', type=str, default='multi_outcome_subgroups_adhd_subgroups.csv',\n",
    "                        help='Path to the ADHD subgroups metrics file')\n",
    "    parser.add_argument('--sex_subgroups', type=str, default='multi_outcome_subgroups_sex_subgroups.csv',\n",
    "                        help='Path to the Sex_F subgroups metrics file')\n",
    "    parser.add_argument('--output_dir', type=str, default='specialized_models_results',\n",
    "                        help='Directory to save outputs')\n",
    "    parser.add_argument('--output_file', type=str, default='specialized_models_submission.csv',\n",
    "                        help='Name of the output submission file')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(f\"\\nRunning specialized models with the following parameters:\")\n",
    "    print(f\"Details file: {args.details}\")\n",
    "    print(f\"ADHD subgroups file: {args.adhd_subgroups}\")\n",
    "    print(f\"Sex_F subgroups file: {args.sex_subgroups}\")\n",
    "    print(f\"Output directory: {args.output_dir}\")\n",
    "    print(f\"Output file: {args.output_file}\")\n",
    "    \n",
    "    # Create specialized models submission\n",
    "    submission_df = create_specialized_models_submission(\n",
    "        details_file=args.details,\n",
    "        adhd_subgroups_file=args.adhd_subgroups,\n",
    "        sex_subgroups_file=args.sex_subgroups,\n",
    "        output_dir=args.output_dir,\n",
    "        output_file=args.output_file\n",
    "    )\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Default file paths - adjust these to match your file locations\n",
    "    details_file = 'multi_outcome_subgroups_details.csv'\n",
    "    adhd_subgroups_file = 'multi_outcome_subgroups_adhd_subgroups.csv'\n",
    "    sex_subgroups_file = 'multi_outcome_subgroups_sex_subgroups.csv'\n",
    "    output_dir = 'specialized_models_results'\n",
    "    \n",
    "    # IMPORTANT: Change these file paths to the actual paths on your system\n",
    "    # details_file = r'C:\\Users\\abdur\\vs_code\\sidra\\multi_outcome_subgroups_details.csv'\n",
    "    # adhd_subgroups_file = r'C:\\Users\\abdur\\vs_code\\sidra\\multi_outcome_subgroups_adhd_subgroups.csv'\n",
    "    # sex_subgroups_file = r'C:\\Users\\abdur\\vs_code\\sidra\\multi_outcome_subgroups_sex_subgroups.csv'\n",
    "    \n",
    "    # Create specialized models submission\n",
    "    submission_df = create_specialized_models_submission(\n",
    "        details_file=details_file,\n",
    "        adhd_subgroups_file=adhd_subgroups_file,\n",
    "        sex_subgroups_file=sex_subgroups_file,\n",
    "        output_dir=output_dir,\n",
    "        output_file='specialized_models_submission.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded details file with 304 rows\n",
      "Columns in details file: ['participant_id', 'ADHD_subgroup', 'Sex_F_subgroup', 'ADHD_Probability', 'Sex_F_Probability', 'ADHD_Threshold', 'Sex_F_Threshold', 'ADHD_Prediction', 'Sex_F_Prediction']\n",
      "Loaded ADHD subgroups file with 3 subgroups\n",
      "Loaded Sex_F subgroups file with 3 subgroups\n",
      "\n",
      "Best ADHD subgroup: 2.0 with sensitivity 0.9032\n",
      "Best Sex_F subgroup: 1.0 with sensitivity 0.9167\n",
      "ADHD threshold from best subgroup: 0.0200\n",
      "Sex_F threshold from best subgroup: 0.1500\n",
      "\n",
      "Submission file saved to: specialized_models_results\\specialized_models_submission.csv\n",
      "\n",
      "Class distribution in specialized predictions:\n",
      "ADHD positive: 291 (95.7%)\n",
      "Sex_F positive: 280 (92.1%)\n",
      "\n",
      "Formatted predictions:\n",
      "participant_id,ADHD_Outcome,Sex_F\n",
      "Cfwaf5FX7jWK,1,1\n",
      "vhGrzmvA3Hjq,1,1\n",
      "ULliyEXjy4OV,1,1\n",
      "LZfeAb1xMtql,1,1\n",
      "EnFOUv0YK1RG,1,1\n",
      "3VbkvJ22j9Fu,1,1\n",
      "PRKZcnOgqcuk,1,1\n",
      "DuVUuyMZi5qV,1,1\n",
      "uM4etVLZrgMg,1,1\n",
      "BpzyExrET5ta,1,1\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Specify your file paths here\n",
    "details_file = r'C:\\Users\\abdur\\vs_code\\sidra\\multi_outcome_subgroups_details.csv'\n",
    "adhd_subgroups_file = r'C:\\Users\\abdur\\vs_code\\sidra\\multi_outcome_subgroups_adhd_subgroups.csv'\n",
    "sex_subgroups_file = r'C:\\Users\\abdur\\vs_code\\sidra\\multi_outcome_subgroups_sex_subgroups.csv'\n",
    "output_dir = 'specialized_models_results'\n",
    "output_file = 'specialized_models_submission.csv'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load the detailed predictions file\n",
    "try:\n",
    "    details_df = pd.read_csv(details_file)\n",
    "    print(f\"Loaded details file with {len(details_df)} rows\")\n",
    "    print(f\"Columns in details file: {details_df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading details file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load the subgroup metrics files\n",
    "try:\n",
    "    adhd_subgroups = pd.read_csv(adhd_subgroups_file)\n",
    "    sex_subgroups = pd.read_csv(sex_subgroups_file)\n",
    "    \n",
    "    print(f\"Loaded ADHD subgroups file with {len(adhd_subgroups)} subgroups\")\n",
    "    print(f\"Loaded Sex_F subgroups file with {len(sex_subgroups)} subgroups\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading subgroups files: {e}\")\n",
    "    raise\n",
    "\n",
    "# Find the best subgroup with highest sensitivity for each target\n",
    "adhd_best_subgroup = adhd_subgroups.loc[adhd_subgroups['sensitivity'].idxmax()]\n",
    "sex_best_subgroup = sex_subgroups.loc[sex_subgroups['sensitivity'].idxmax()]\n",
    "\n",
    "print(f\"\\nBest ADHD subgroup: {adhd_best_subgroup['subgroup']} with sensitivity {adhd_best_subgroup['sensitivity']:.4f}\")\n",
    "print(f\"Best Sex_F subgroup: {sex_best_subgroup['subgroup']} with sensitivity {sex_best_subgroup['sensitivity']:.4f}\")\n",
    "\n",
    "# Get the thresholds for these best subgroups\n",
    "adhd_best_threshold = adhd_best_subgroup['threshold']\n",
    "sex_best_threshold = sex_best_subgroup['threshold']\n",
    "\n",
    "print(f\"ADHD threshold from best subgroup: {adhd_best_threshold:.4f}\")\n",
    "print(f\"Sex_F threshold from best subgroup: {sex_best_threshold:.4f}\")\n",
    "\n",
    "# Apply thresholds to generate predictions\n",
    "details_df['ADHD_Specialized_Prediction'] = (details_df['ADHD_Probability'] >= adhd_best_threshold).astype(int)\n",
    "details_df['Sex_F_Specialized_Prediction'] = (details_df['Sex_F_Probability'] >= sex_best_threshold).astype(int)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'participant_id': details_df['participant_id'],\n",
    "    'ADHD_Outcome': details_df['ADHD_Specialized_Prediction'],\n",
    "    'Sex_F': details_df['Sex_F_Specialized_Prediction']\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission_path = os.path.join(output_dir, output_file)\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission file saved to: {submission_path}\")\n",
    "\n",
    "# Calculate class distribution\n",
    "adhd_positive = submission_df['ADHD_Outcome'].sum()\n",
    "sex_positive = submission_df['Sex_F'].sum()\n",
    "\n",
    "print(f\"\\nClass distribution in specialized predictions:\")\n",
    "print(f\"ADHD positive: {adhd_positive} ({adhd_positive/len(submission_df)*100:.1f}%)\")\n",
    "print(f\"Sex_F positive: {sex_positive} ({sex_positive/len(submission_df)*100:.1f}%)\")\n",
    "\n",
    "# Print formatted outputs\n",
    "print(\"\\nFormatted predictions:\")\n",
    "print(\"participant_id,ADHD_Outcome,Sex_F\")\n",
    "for _, row in submission_df.head(10).iterrows():\n",
    "    print(f\"{row['participant_id']},{row['ADHD_Outcome']},{row['Sex_F']}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10712530,
     "sourceId": 90566,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
